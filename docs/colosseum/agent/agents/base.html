<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>colosseum.agent.agents.base API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>colosseum.agent.agents.base</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import abc
import random
from typing import TYPE_CHECKING, Any, Dict, Union

import dm_env
import numpy as np
from ray import tune

from colosseum.utils.acme.specs import MDPSpec

if TYPE_CHECKING:
    from colosseum.mdp import ACTION_TYPE, OBSERVATION_TYPE
    from colosseum.agent.actors import ACTOR_TYPES
    from colosseum.agent.mdp_models import MODEL_TYPES


class BaseAgent(abc.ABC):
    @staticmethod
    @abc.abstractmethod
    def is_episodic() -&gt; bool:
        &#34;&#34;&#34;
        returns whether the agent is suited for the episodic setting.
        &#34;&#34;&#34;

    @abc.abstractmethod
    def __init__(
        self,
        seed: int,
        environment_spec: &#34;MDPSpec&#34;,
        mdp_model: Union[None, &#34;MODEL_TYPES&#34;],
        actor: &#34;ACTOR_TYPES&#34;,
        optimization_horizon: int,
    ):
        &#34;&#34;&#34;
        Parameters
        ----------
        seed : int
            is the random seed.
        environment_spec : MDPSpec
            provides the full specification of the MDP.
        mdp_model : BaseMDP_Model
            is the component of the agent that encapsulates the knowledge acquired from the interactions with
            the MDP.
        actor : BaseActor
            calculates an action given the corresponding MDP model.
        optimization_horizon : int
            is the total number of interactions that the agent is expected to have with the MDP.
        &#34;&#34;&#34;
        self._environment_spec = environment_spec
        self._mdp_model = mdp_model
        self._actor = actor
        self._optimization_horizon = optimization_horizon
        self._time_horizon = environment_spec.time_horizon

        self._rng = np.random.RandomState(seed)
        self._rng_fast = random.Random(seed)

    @abc.abstractmethod
    def episode_end_update(self):
        &#34;&#34;&#34;
        is in charge of any change that should happen when an episode ends. In the infinite horizon case, we refer to
        artificial episodes.
        &#34;&#34;&#34;

    @abc.abstractmethod
    def before_start_interacting(self):
        &#34;&#34;&#34;
        is called before the agent starts interacting with the MDP.
        &#34;&#34;&#34;

    def is_episode_end(
        self,
        ts_t: dm_env.TimeStep,
        a_t: &#34;ACTION_TYPE&#34;,
        ts_tp1: dm_env.TimeStep,
        time_step: int,
    ) -&gt; bool:
        &#34;&#34;&#34;
        checks whether the episode is terminated. By default, this checks whether the current time step
        exceeds the time horizon. In the continuous case, this can be used to define artificial episodes.
        &#34;&#34;&#34;
        return ts_tp1.last()

    def select_action(
        self, ts: dm_env.TimeStep, time_step: int
    ) -&gt; &#34;ACTION_TYPE&#34;:
        &#34;&#34;&#34;

        Parameters
        ----------
        ts : dm_env.TimeStep
            the observation for which the agent is required to calculate the next action.
        time_step : int
            the current time step of the environment. In the episodic case, this refers to the in-episode time step,
            whereas in the continuous case this refers to the number of previous interactions.

        Returns
        -------
        action : ACTION_TYPE
            the action that the agent suggests to take given the observation and the time step.
        &#34;&#34;&#34;
        return self._actor.select_action(ts, time_step)

    def step_update(
        self, ts_t: dm_env.TimeStep, a_t: &#34;ACTION_TYPE&#34;, ts_tp1: dm_env.TimeStep, h: int
    ):
        &#34;&#34;&#34;
        updates the MDP model with the _compute_transition information given in input.
        &#34;&#34;&#34;
        if self._mdp_model:
            self._mdp_model.step_update(ts_t, a_t, ts_tp1, h)

    def agent_logs(self):
        &#34;&#34;&#34;
        is called during the agent MDP interaction at lagging time. It can be used to log additional information.
        &#34;&#34;&#34;
        pass

    @property
    @abc.abstractmethod
    def current_optimal_stochastic_policy(self) -&gt; np.ndarray:
        &#34;&#34;&#34;
        returns the estimates of the best optimal policy given the current knowledge of the agent. It must be return in
        the stochastic.
        &#34;&#34;&#34;

    @staticmethod
    @abc.abstractmethod
    def get_hyperparameters_search_spaces() -&gt; Dict[str, tune.sample.Domain]:
        &#34;&#34;&#34;
        returns a dictionary with key value pairs corresponding to hyperparameter name and ray.tune sampler.
        &#34;&#34;&#34;

    @staticmethod
    @abc.abstractmethod
    def produce_gin_file_from_hyperparameters(
        hyperparameters: Dict[str, Any], index: int = 0
    ):
        pass

    @staticmethod
    @abc.abstractmethod
    def get_agent_instance_from_hyperparameters(
        seed: int,
        optimization_horizon: int,
        mdp_specs: MDPSpec,
        hyperparameters: Dict[str, Any],
    ) -&gt; &#34;BaseAgent&#34;:
        &#34;&#34;&#34;
        returns an agent instance for the mdp specification and agent hyperparameters given in input.
        &#34;&#34;&#34;</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="colosseum.agent.agents.base.BaseAgent"><code class="flex name class">
<span>class <span class="ident">BaseAgent</span></span>
<span>(</span><span>seed: int, environment_spec: MDPSpec, mdp_model: Optional[None], actor: ACTOR_TYPES, optimization_horizon: int)</span>
</code></dt>
<dd>
<div class="desc"><p>Helper class that provides a standard way to create an ABC using
inheritance.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>seed</code></strong> :&ensp;<code>int</code></dt>
<dd>is the random seed.</dd>
<dt><strong><code>environment_spec</code></strong> :&ensp;<code>MDPSpec</code></dt>
<dd>provides the full specification of the MDP.</dd>
<dt><strong><code>mdp_model</code></strong> :&ensp;<code>BaseMDP_Model</code></dt>
<dd>is the component of the agent that encapsulates the knowledge acquired from the interactions with
the MDP.</dd>
<dt><strong><code>actor</code></strong> :&ensp;<code>BaseActor</code></dt>
<dd>calculates an action given the corresponding MDP model.</dd>
<dt><strong><code>optimization_horizon</code></strong> :&ensp;<code>int</code></dt>
<dd>is the total number of interactions that the agent is expected to have with the MDP.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class BaseAgent(abc.ABC):
    @staticmethod
    @abc.abstractmethod
    def is_episodic() -&gt; bool:
        &#34;&#34;&#34;
        returns whether the agent is suited for the episodic setting.
        &#34;&#34;&#34;

    @abc.abstractmethod
    def __init__(
        self,
        seed: int,
        environment_spec: &#34;MDPSpec&#34;,
        mdp_model: Union[None, &#34;MODEL_TYPES&#34;],
        actor: &#34;ACTOR_TYPES&#34;,
        optimization_horizon: int,
    ):
        &#34;&#34;&#34;
        Parameters
        ----------
        seed : int
            is the random seed.
        environment_spec : MDPSpec
            provides the full specification of the MDP.
        mdp_model : BaseMDP_Model
            is the component of the agent that encapsulates the knowledge acquired from the interactions with
            the MDP.
        actor : BaseActor
            calculates an action given the corresponding MDP model.
        optimization_horizon : int
            is the total number of interactions that the agent is expected to have with the MDP.
        &#34;&#34;&#34;
        self._environment_spec = environment_spec
        self._mdp_model = mdp_model
        self._actor = actor
        self._optimization_horizon = optimization_horizon
        self._time_horizon = environment_spec.time_horizon

        self._rng = np.random.RandomState(seed)
        self._rng_fast = random.Random(seed)

    @abc.abstractmethod
    def episode_end_update(self):
        &#34;&#34;&#34;
        is in charge of any change that should happen when an episode ends. In the infinite horizon case, we refer to
        artificial episodes.
        &#34;&#34;&#34;

    @abc.abstractmethod
    def before_start_interacting(self):
        &#34;&#34;&#34;
        is called before the agent starts interacting with the MDP.
        &#34;&#34;&#34;

    def is_episode_end(
        self,
        ts_t: dm_env.TimeStep,
        a_t: &#34;ACTION_TYPE&#34;,
        ts_tp1: dm_env.TimeStep,
        time_step: int,
    ) -&gt; bool:
        &#34;&#34;&#34;
        checks whether the episode is terminated. By default, this checks whether the current time step
        exceeds the time horizon. In the continuous case, this can be used to define artificial episodes.
        &#34;&#34;&#34;
        return ts_tp1.last()

    def select_action(
        self, ts: dm_env.TimeStep, time_step: int
    ) -&gt; &#34;ACTION_TYPE&#34;:
        &#34;&#34;&#34;

        Parameters
        ----------
        ts : dm_env.TimeStep
            the observation for which the agent is required to calculate the next action.
        time_step : int
            the current time step of the environment. In the episodic case, this refers to the in-episode time step,
            whereas in the continuous case this refers to the number of previous interactions.

        Returns
        -------
        action : ACTION_TYPE
            the action that the agent suggests to take given the observation and the time step.
        &#34;&#34;&#34;
        return self._actor.select_action(ts, time_step)

    def step_update(
        self, ts_t: dm_env.TimeStep, a_t: &#34;ACTION_TYPE&#34;, ts_tp1: dm_env.TimeStep, h: int
    ):
        &#34;&#34;&#34;
        updates the MDP model with the _compute_transition information given in input.
        &#34;&#34;&#34;
        if self._mdp_model:
            self._mdp_model.step_update(ts_t, a_t, ts_tp1, h)

    def agent_logs(self):
        &#34;&#34;&#34;
        is called during the agent MDP interaction at lagging time. It can be used to log additional information.
        &#34;&#34;&#34;
        pass

    @property
    @abc.abstractmethod
    def current_optimal_stochastic_policy(self) -&gt; np.ndarray:
        &#34;&#34;&#34;
        returns the estimates of the best optimal policy given the current knowledge of the agent. It must be return in
        the stochastic.
        &#34;&#34;&#34;

    @staticmethod
    @abc.abstractmethod
    def get_hyperparameters_search_spaces() -&gt; Dict[str, tune.sample.Domain]:
        &#34;&#34;&#34;
        returns a dictionary with key value pairs corresponding to hyperparameter name and ray.tune sampler.
        &#34;&#34;&#34;

    @staticmethod
    @abc.abstractmethod
    def produce_gin_file_from_hyperparameters(
        hyperparameters: Dict[str, Any], index: int = 0
    ):
        pass

    @staticmethod
    @abc.abstractmethod
    def get_agent_instance_from_hyperparameters(
        seed: int,
        optimization_horizon: int,
        mdp_specs: MDPSpec,
        hyperparameters: Dict[str, Any],
    ) -&gt; &#34;BaseAgent&#34;:
        &#34;&#34;&#34;
        returns an agent instance for the mdp specification and agent hyperparameters given in input.
        &#34;&#34;&#34;</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>abc.ABC</li>
</ul>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="colosseum.agent.agents.episodic.posterior_sampling.PSRLEpisodic" href="episodic/posterior_sampling.html#colosseum.agent.agents.episodic.posterior_sampling.PSRLEpisodic">PSRLEpisodic</a></li>
<li><a title="colosseum.agent.agents.episodic.q_learning.QLearningEpisodic" href="episodic/q_learning.html#colosseum.agent.agents.episodic.q_learning.QLearningEpisodic">QLearningEpisodic</a></li>
<li><a title="colosseum.agent.agents.infinite_horizon.posterior_sampling.PSRLContinuous" href="infinite_horizon/posterior_sampling.html#colosseum.agent.agents.infinite_horizon.posterior_sampling.PSRLContinuous">PSRLContinuous</a></li>
<li><a title="colosseum.agent.agents.infinite_horizon.q_learning.QLearningContinuous" href="infinite_horizon/q_learning.html#colosseum.agent.agents.infinite_horizon.q_learning.QLearningContinuous">QLearningContinuous</a></li>
<li><a title="colosseum.agent.agents.infinite_horizon.ucrl2.UCRL2Continuous" href="infinite_horizon/ucrl2.html#colosseum.agent.agents.infinite_horizon.ucrl2.UCRL2Continuous">UCRL2Continuous</a></li>
<li><a title="colosseum.agent.agents.random.RandomAgent" href="random.html#colosseum.agent.agents.random.RandomAgent">RandomAgent</a></li>
</ul>
<h3>Static methods</h3>
<dl>
<dt id="colosseum.agent.agents.base.BaseAgent.get_agent_instance_from_hyperparameters"><code class="name flex">
<span>def <span class="ident">get_agent_instance_from_hyperparameters</span></span>(<span>seed: int, optimization_horizon: int, mdp_specs: <a title="colosseum.utils.acme.specs.MDPSpec" href="../../utils/acme/specs.html#colosseum.utils.acme.specs.MDPSpec">MDPSpec</a>, hyperparameters: Dict[str, Any]) ‑> <a title="colosseum.agent.agents.base.BaseAgent" href="#colosseum.agent.agents.base.BaseAgent">BaseAgent</a></span>
</code></dt>
<dd>
<div class="desc"><p>returns an agent instance for the mdp specification and agent hyperparameters given in input.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
@abc.abstractmethod
def get_agent_instance_from_hyperparameters(
    seed: int,
    optimization_horizon: int,
    mdp_specs: MDPSpec,
    hyperparameters: Dict[str, Any],
) -&gt; &#34;BaseAgent&#34;:
    &#34;&#34;&#34;
    returns an agent instance for the mdp specification and agent hyperparameters given in input.
    &#34;&#34;&#34;</code></pre>
</details>
</dd>
<dt id="colosseum.agent.agents.base.BaseAgent.get_hyperparameters_search_spaces"><code class="name flex">
<span>def <span class="ident">get_hyperparameters_search_spaces</span></span>(<span>) ‑> Dict[str, ray.tune.sample.Domain]</span>
</code></dt>
<dd>
<div class="desc"><p>returns a dictionary with key value pairs corresponding to hyperparameter name and ray.tune sampler.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
@abc.abstractmethod
def get_hyperparameters_search_spaces() -&gt; Dict[str, tune.sample.Domain]:
    &#34;&#34;&#34;
    returns a dictionary with key value pairs corresponding to hyperparameter name and ray.tune sampler.
    &#34;&#34;&#34;</code></pre>
</details>
</dd>
<dt id="colosseum.agent.agents.base.BaseAgent.is_episodic"><code class="name flex">
<span>def <span class="ident">is_episodic</span></span>(<span>) ‑> bool</span>
</code></dt>
<dd>
<div class="desc"><p>returns whether the agent is suited for the episodic setting.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
@abc.abstractmethod
def is_episodic() -&gt; bool:
    &#34;&#34;&#34;
    returns whether the agent is suited for the episodic setting.
    &#34;&#34;&#34;</code></pre>
</details>
</dd>
<dt id="colosseum.agent.agents.base.BaseAgent.produce_gin_file_from_hyperparameters"><code class="name flex">
<span>def <span class="ident">produce_gin_file_from_hyperparameters</span></span>(<span>hyperparameters: Dict[str, Any], index: int = 0)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
@abc.abstractmethod
def produce_gin_file_from_hyperparameters(
    hyperparameters: Dict[str, Any], index: int = 0
):
    pass</code></pre>
</details>
</dd>
</dl>
<h3>Instance variables</h3>
<dl>
<dt id="colosseum.agent.agents.base.BaseAgent.current_optimal_stochastic_policy"><code class="name">var <span class="ident">current_optimal_stochastic_policy</span> : numpy.ndarray</code></dt>
<dd>
<div class="desc"><p>returns the estimates of the best optimal policy given the current knowledge of the agent. It must be return in
the stochastic.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
@abc.abstractmethod
def current_optimal_stochastic_policy(self) -&gt; np.ndarray:
    &#34;&#34;&#34;
    returns the estimates of the best optimal policy given the current knowledge of the agent. It must be return in
    the stochastic.
    &#34;&#34;&#34;</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="colosseum.agent.agents.base.BaseAgent.agent_logs"><code class="name flex">
<span>def <span class="ident">agent_logs</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>is called during the agent MDP interaction at lagging time. It can be used to log additional information.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def agent_logs(self):
    &#34;&#34;&#34;
    is called during the agent MDP interaction at lagging time. It can be used to log additional information.
    &#34;&#34;&#34;
    pass</code></pre>
</details>
</dd>
<dt id="colosseum.agent.agents.base.BaseAgent.before_start_interacting"><code class="name flex">
<span>def <span class="ident">before_start_interacting</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>is called before the agent starts interacting with the MDP.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@abc.abstractmethod
def before_start_interacting(self):
    &#34;&#34;&#34;
    is called before the agent starts interacting with the MDP.
    &#34;&#34;&#34;</code></pre>
</details>
</dd>
<dt id="colosseum.agent.agents.base.BaseAgent.episode_end_update"><code class="name flex">
<span>def <span class="ident">episode_end_update</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>is in charge of any change that should happen when an episode ends. In the infinite horizon case, we refer to
artificial episodes.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@abc.abstractmethod
def episode_end_update(self):
    &#34;&#34;&#34;
    is in charge of any change that should happen when an episode ends. In the infinite horizon case, we refer to
    artificial episodes.
    &#34;&#34;&#34;</code></pre>
</details>
</dd>
<dt id="colosseum.agent.agents.base.BaseAgent.is_episode_end"><code class="name flex">
<span>def <span class="ident">is_episode_end</span></span>(<span>self, ts_t: dm_env._environment.TimeStep, a_t: ACTION_TYPE, ts_tp1: dm_env._environment.TimeStep, time_step: int) ‑> bool</span>
</code></dt>
<dd>
<div class="desc"><p>checks whether the episode is terminated. By default, this checks whether the current time step
exceeds the time horizon. In the continuous case, this can be used to define artificial episodes.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def is_episode_end(
    self,
    ts_t: dm_env.TimeStep,
    a_t: &#34;ACTION_TYPE&#34;,
    ts_tp1: dm_env.TimeStep,
    time_step: int,
) -&gt; bool:
    &#34;&#34;&#34;
    checks whether the episode is terminated. By default, this checks whether the current time step
    exceeds the time horizon. In the continuous case, this can be used to define artificial episodes.
    &#34;&#34;&#34;
    return ts_tp1.last()</code></pre>
</details>
</dd>
<dt id="colosseum.agent.agents.base.BaseAgent.select_action"><code class="name flex">
<span>def <span class="ident">select_action</span></span>(<span>self, ts: dm_env._environment.TimeStep, time_step: int) ‑> ACTION_TYPE</span>
</code></dt>
<dd>
<div class="desc"><h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>ts</code></strong> :&ensp;<code>dm_env.TimeStep</code></dt>
<dd>the observation for which the agent is required to calculate the next action.</dd>
<dt><strong><code>time_step</code></strong> :&ensp;<code>int</code></dt>
<dd>the current time step of the environment. In the episodic case, this refers to the in-episode time step,
whereas in the continuous case this refers to the number of previous interactions.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>action</code></strong> :&ensp;<code>ACTION_TYPE</code></dt>
<dd>the action that the agent suggests to take given the observation and the time step.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def select_action(
    self, ts: dm_env.TimeStep, time_step: int
) -&gt; &#34;ACTION_TYPE&#34;:
    &#34;&#34;&#34;

    Parameters
    ----------
    ts : dm_env.TimeStep
        the observation for which the agent is required to calculate the next action.
    time_step : int
        the current time step of the environment. In the episodic case, this refers to the in-episode time step,
        whereas in the continuous case this refers to the number of previous interactions.

    Returns
    -------
    action : ACTION_TYPE
        the action that the agent suggests to take given the observation and the time step.
    &#34;&#34;&#34;
    return self._actor.select_action(ts, time_step)</code></pre>
</details>
</dd>
<dt id="colosseum.agent.agents.base.BaseAgent.step_update"><code class="name flex">
<span>def <span class="ident">step_update</span></span>(<span>self, ts_t: dm_env._environment.TimeStep, a_t: ACTION_TYPE, ts_tp1: dm_env._environment.TimeStep, h: int)</span>
</code></dt>
<dd>
<div class="desc"><p>updates the MDP model with the _compute_transition information given in input.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def step_update(
    self, ts_t: dm_env.TimeStep, a_t: &#34;ACTION_TYPE&#34;, ts_tp1: dm_env.TimeStep, h: int
):
    &#34;&#34;&#34;
    updates the MDP model with the _compute_transition information given in input.
    &#34;&#34;&#34;
    if self._mdp_model:
        self._mdp_model.step_update(ts_t, a_t, ts_tp1, h)</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="colosseum.agent.agents" href="index.html">colosseum.agent.agents</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="colosseum.agent.agents.base.BaseAgent" href="#colosseum.agent.agents.base.BaseAgent">BaseAgent</a></code></h4>
<ul class="">
<li><code><a title="colosseum.agent.agents.base.BaseAgent.agent_logs" href="#colosseum.agent.agents.base.BaseAgent.agent_logs">agent_logs</a></code></li>
<li><code><a title="colosseum.agent.agents.base.BaseAgent.before_start_interacting" href="#colosseum.agent.agents.base.BaseAgent.before_start_interacting">before_start_interacting</a></code></li>
<li><code><a title="colosseum.agent.agents.base.BaseAgent.current_optimal_stochastic_policy" href="#colosseum.agent.agents.base.BaseAgent.current_optimal_stochastic_policy">current_optimal_stochastic_policy</a></code></li>
<li><code><a title="colosseum.agent.agents.base.BaseAgent.episode_end_update" href="#colosseum.agent.agents.base.BaseAgent.episode_end_update">episode_end_update</a></code></li>
<li><code><a title="colosseum.agent.agents.base.BaseAgent.get_agent_instance_from_hyperparameters" href="#colosseum.agent.agents.base.BaseAgent.get_agent_instance_from_hyperparameters">get_agent_instance_from_hyperparameters</a></code></li>
<li><code><a title="colosseum.agent.agents.base.BaseAgent.get_hyperparameters_search_spaces" href="#colosseum.agent.agents.base.BaseAgent.get_hyperparameters_search_spaces">get_hyperparameters_search_spaces</a></code></li>
<li><code><a title="colosseum.agent.agents.base.BaseAgent.is_episode_end" href="#colosseum.agent.agents.base.BaseAgent.is_episode_end">is_episode_end</a></code></li>
<li><code><a title="colosseum.agent.agents.base.BaseAgent.is_episodic" href="#colosseum.agent.agents.base.BaseAgent.is_episodic">is_episodic</a></code></li>
<li><code><a title="colosseum.agent.agents.base.BaseAgent.produce_gin_file_from_hyperparameters" href="#colosseum.agent.agents.base.BaseAgent.produce_gin_file_from_hyperparameters">produce_gin_file_from_hyperparameters</a></code></li>
<li><code><a title="colosseum.agent.agents.base.BaseAgent.select_action" href="#colosseum.agent.agents.base.BaseAgent.select_action">select_action</a></code></li>
<li><code><a title="colosseum.agent.agents.base.BaseAgent.step_update" href="#colosseum.agent.agents.base.BaseAgent.step_update">step_update</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>