<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>colosseum.mdp.simple_grid.base API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>colosseum.mdp.simple_grid.base</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import abc
from dataclasses import dataclass
from enum import IntEnum
from typing import TYPE_CHECKING, Any, Dict, List, Tuple, Type, Union

import gin
import numpy as np
from scipy.stats import beta, rv_continuous

from colosseum.mdp import BaseMDP
from colosseum.mdp.utils.custom_samplers import NextStateSampler
from colosseum.utils.miscellanea import check_distributions, deterministic, get_dist

if TYPE_CHECKING:
    from colosseum.mdp import ACTION_TYPE, NODE_TYPE


@dataclass(frozen=True)
class SimpleGridNode:
    X: int
    Y: int

    def __str__(self):
        return f&#34;X={self.X},Y={self.Y}&#34;

    def __iter__(self):
        return iter((self.X, self.Y))


class SimpleGridAction(IntEnum):
    &#34;&#34;&#34;The action available in the SimpleGrid MDP.&#34;&#34;&#34;

    UP = 0
    RIGHT = 1
    DOWN = 2
    LEFT = 3
    NO_OP = 4


@gin.constants_from_enum
class SimpleGridReward(IntEnum):
    &#34;&#34;&#34;The reward types available in the SimpleGrid MDP.&#34;&#34;&#34;

    AND = 0
    NAND = 1
    OR = 2
    XOR = 3


class SimpleGridMDP(BaseMDP, abc.ABC):
    @staticmethod
    def does_seed_change_MDP_structure() -&gt; bool:
        return True

    @staticmethod
    def _sample_parameters(
        n: int, is_episodic: bool, seed: int = None
    ) -&gt; List[Dict[str, Any]]:
        rng = np.random.RandomState(np.random.randint(10_000) if seed is None else seed)
        samples = []
        for _ in range(n):
            p_rand, p_lazy, _ = 0.9 * np.random.dirichlet([0.2, 0.2, 5])
            sample = dict(
                size=int(
                    (
                        1
                        + np.minimum((800 / (100 * np.random.random() + 35)), 25)
                        * (0.8 if is_episodic else 1)
                    )
                ),
                n_starting_states=rng.randint(1, 5),
                p_rand=p_rand,
                p_lazy=p_lazy,
                make_reward_stochastic=rng.choice([True, False]),
                variance_multipliers=2 * rng.random() + 0.005,
            )
            sample[&#34;p_rand&#34;] = None if sample[&#34;p_rand&#34;] &lt; 0.01 else sample[&#34;p_rand&#34;]
            sample[&#34;p_lazy&#34;] = None if sample[&#34;p_lazy&#34;] &lt; 0.01 else sample[&#34;p_lazy&#34;]

            if sample[&#34;make_reward_stochastic&#34;]:
                sample[&#34;sub_optimal_distribution&#34;] = beta(
                    sample[&#34;variance_multipliers&#34;],
                    sample[&#34;variance_multipliers&#34;] * (10 / 0.2 - 1),
                )
                sample[&#34;optimal_distribution&#34;] = beta(
                    sample[&#34;variance_multipliers&#34;],
                    sample[&#34;variance_multipliers&#34;] * (1 / 0.9 - 1),
                )
                sample[&#34;other_distribution&#34;] = beta(
                    sample[&#34;variance_multipliers&#34;],
                    sample[&#34;variance_multipliers&#34;] * (1 / 0.2 - 1),
                )
            else:
                sample[&#34;sub_optimal_distribution&#34;] = deterministic(0.0)
                sample[&#34;optimal_distribution&#34;] = deterministic(1.0)
                sample[&#34;other_distribution&#34;] = deterministic(0.5)
            samples.append(sample)
        return samples

    @staticmethod
    def get_node_class() -&gt; Type[&#34;NODE_TYPE&#34;]:
        return SimpleGridNode

    @property
    def n_actions(self) -&gt; int:
        return len(SimpleGridAction)

    def _get_next_nodes_parameters(
        self, node: &#34;NODE_TYPE&#34;, action: &#34;ACTION_TYPE&#34;
    ) -&gt; Tuple[Tuple[dict, float], ...]:
        if action == SimpleGridAction.UP:
            return ((dict(X=node.X, Y=min(node.Y + 1, self._size - 1)), 1.0),)
        if action == SimpleGridAction.RIGHT:
            return ((dict(X=min(node.X + 1, self._size - 1), Y=node.Y), 1.0),)
        if action == SimpleGridAction.DOWN:
            return ((dict(X=node.X, Y=max(node.Y - 1, 0)), 1.0),)
        if action == SimpleGridAction.LEFT:
            return ((dict(X=max(node.X - 1, 0), Y=node.Y), 1.0),)
        if action == SimpleGridAction.NO_OP:
            return ((dict(X=node.X, Y=node.Y), 1.0),)

    @staticmethod
    def _is_corner_loop(node, next_node, size):
        return (
            node.X == next_node.X
            and node.Y == next_node.Y
            and node.X in [0, size - 1]
            and node.Y in [0, size - 1]
        )

    def _get_reward_distribution(
        self, node: &#34;NODE_TYPE&#34;, action: &#34;ACTION_TYPE&#34;, next_node: &#34;NODE_TYPE&#34;
    ) -&gt; rv_continuous:
        # Corner nodes
        if SimpleGridMDP._is_corner_loop(node, next_node, self._size):
            if (
                (self._reward_type == SimpleGridReward.AND and (node.X and node.Y))
                or (
                    self._reward_type == SimpleGridReward.NAND
                    and not (node.X and node.Y)
                )
                or (self._reward_type == SimpleGridReward.OR and (node.X | node.Y))
                or (self._reward_type == SimpleGridReward.XOR and (node.X ^ node.Y))
            ):
                return self._optimal_distribution
            else:
                return self._sub_optimal_distribution
        else:
            return self._other_distribution

    def _calculate_starting_nodes(self):
        center = np.array(((self._size - 1) / 2, (self._size - 1) / 2))
        distances = np.empty((self._size, self._size))
        for x in range(self._size):
            for y in range(self._size):
                distances[x, y] = ((np.array((x, y)) - center) ** 2).sum()

        batch: list = np.array(np.where(distances == distances.min())).T.tolist()
        self._rng.shuffle(batch)
        while not np.all(distances == np.inf):
            distances[batch[0][0], batch[0][1]] = np.inf
            yield batch[0]
            batch.pop(0)
            if len(batch) == 0:
                batch: list = np.array(
                    np.where(distances == distances.min())
                ).T.tolist()

    def _get_starting_node_sampler(self) -&gt; NextStateSampler:
        starting_nodes_iter = self._calculate_starting_nodes()
        self.__possible_starting_nodes = [
            self.get_node_class()(*next(starting_nodes_iter))
            for _ in range((self._size - 1) ** 2)
        ]
        starting_nodes = self._possible_starting_nodes[: self._n_starting_states]
        self._rng.shuffle(starting_nodes)
        if len(starting_nodes) == 1:
            return NextStateSampler(next_nodes=starting_nodes)
        return NextStateSampler(
            next_nodes=starting_nodes,
            probs=[1 / self._n_starting_states for _ in range(self._n_starting_states)],
            seed=self._produce_random_seed(),
        )

    def _check_parameters_in_input(self):
        super(SimpleGridMDP, self)._check_parameters_in_input()

        assert self._n_starting_states &lt;= (self._size - 1) ** 2
        assert self._optimal_mean_reward - 0.1 &gt; self._sub_optimal_mean_reward

        dists = [
            self._sub_optimal_distribution,
            self._optimal_distribution,
            self._other_distribution,
        ]
        check_distributions(
            dists,
            self._make_reward_stochastic,
        )

    def _get_grid_representation(self, node: &#34;NODE_TYPE&#34;):
        grid = np.zeros((self._size, self._size), dtype=str)
        grid[:, :] = &#34; &#34;

        # Corner nodes
        if self._reward_type == SimpleGridReward.AND:
            grid[0, 0] = &#34;-&#34;
            grid[0, -1] = &#34;-&#34;
            grid[-1, 0] = &#34;-&#34;
            grid[-1, -1] = &#34;+&#34;
        elif self._reward_type == SimpleGridReward.NAND:
            grid[0, 0] = &#34;+&#34;
            grid[0, -1] = &#34;+&#34;
            grid[-1, 0] = &#34;+&#34;
            grid[-1, -1] = &#34;-&#34;
        elif self._reward_type == SimpleGridReward.OR:
            grid[0, 0] = &#34;-&#34;
            grid[0, -1] = &#34;+&#34;
            grid[-1, 0] = &#34;+&#34;
            grid[-1, -1] = &#34;+&#34;
        else:
            grid[0, 0] = &#34;-&#34;
            grid[0, -1] = &#34;+&#34;
            grid[-1, 0] = &#34;+&#34;
            grid[-1, -1] = &#34;-&#34;

        grid[node.Y, node.X] = &#34;A&#34;
        return grid[::-1, :]

    @property
    def _possible_starting_nodes(self) -&gt; List[&#34;NODE_TYPE&#34;]:
        return self.__possible_starting_nodes

    @property
    def parameters(self) -&gt; Dict[str, Any]:
        return {
            **super(SimpleGridMDP, self).parameters,
            **dict(
                size=self._size,
                reward_type=self._reward_type,
                n_starting_states=self._n_starting_states,
                optimal_mean_reward=self._optimal_mean_reward,
                sub_optimal_mean_reward=self._sub_optimal_mean_reward,
                optimal_distribution=self._optimal_distribution,
                sub_optimal_distribution=self._sub_optimal_distribution,
                other_distribution=self._other_distribution,
            ),
        }

    def __init__(
        self,
        seed: int,
        size: int,
        reward_type: SimpleGridReward = SimpleGridReward.XOR,
        n_starting_states: int = 1,
        optimal_mean_reward: float = 0.9,
        sub_optimal_mean_reward: float = 0.2,
        optimal_distribution: Union[Tuple, rv_continuous] = None,
        sub_optimal_distribution: Union[Tuple, rv_continuous] = None,
        other_distribution: Union[Tuple, rv_continuous] = None,
        make_reward_stochastic=False,
        variance_multipliers: float = 1.0,
        **kwargs,
    ):
        if type(sub_optimal_distribution) == tuple:
            sub_optimal_distribution = get_dist(
                sub_optimal_distribution[0], sub_optimal_distribution[1:]
            )
        if type(optimal_distribution) == tuple:
            optimal_distribution = get_dist(
                optimal_distribution[0], optimal_distribution[1:]
            )
        if type(other_distribution) == tuple:
            other_distribution = get_dist(other_distribution[0], other_distribution[1:])

        self._size = size
        self._reward_type = SimpleGridReward(reward_type)
        self._n_starting_states = n_starting_states
        self._optimal_mean_reward = optimal_mean_reward
        self._sub_optimal_mean_reward = sub_optimal_mean_reward
        dists = [
            sub_optimal_distribution,
            optimal_distribution,
            other_distribution,
        ]

        if dists.count(None) == 0:
            self._sub_optimal_distribution = sub_optimal_distribution
            self._optimal_distribution = optimal_distribution
            self._other_distribution = other_distribution
        else:
            if make_reward_stochastic:
                self._sub_optimal_distribution = beta(
                    variance_multipliers,
                    variance_multipliers * (10 / sub_optimal_mean_reward - 1),
                )
                self._optimal_distribution = beta(
                    variance_multipliers,
                    variance_multipliers * (1 / optimal_mean_reward - 1),
                )
                self._other_distribution = beta(
                    variance_multipliers,
                    variance_multipliers * (1 / sub_optimal_mean_reward - 1),
                )
            else:
                self._sub_optimal_distribution = deterministic(0.0)
                self._optimal_distribution = deterministic(1.0)
                self._other_distribution = deterministic(0.5)

        super(SimpleGridMDP, self).__init__(
            seed=seed,
            variance_multipliers=variance_multipliers,
            make_reward_stochastic=make_reward_stochastic,
            **kwargs,
        )</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="colosseum.mdp.simple_grid.base.SimpleGridAction"><code class="flex name class">
<span>class <span class="ident">SimpleGridAction</span></span>
<span>(</span><span>value, names=None, *, module=None, qualname=None, type=None, start=1)</span>
</code></dt>
<dd>
<div class="desc"><p>The action available in the SimpleGrid MDP.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class SimpleGridAction(IntEnum):
    &#34;&#34;&#34;The action available in the SimpleGrid MDP.&#34;&#34;&#34;

    UP = 0
    RIGHT = 1
    DOWN = 2
    LEFT = 3
    NO_OP = 4</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>enum.IntEnum</li>
<li>builtins.int</li>
<li>enum.Enum</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="colosseum.mdp.simple_grid.base.SimpleGridAction.DOWN"><code class="name">var <span class="ident">DOWN</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="colosseum.mdp.simple_grid.base.SimpleGridAction.LEFT"><code class="name">var <span class="ident">LEFT</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="colosseum.mdp.simple_grid.base.SimpleGridAction.NO_OP"><code class="name">var <span class="ident">NO_OP</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="colosseum.mdp.simple_grid.base.SimpleGridAction.RIGHT"><code class="name">var <span class="ident">RIGHT</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="colosseum.mdp.simple_grid.base.SimpleGridAction.UP"><code class="name">var <span class="ident">UP</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
</dd>
<dt id="colosseum.mdp.simple_grid.base.SimpleGridMDP"><code class="flex name class">
<span>class <span class="ident">SimpleGridMDP</span></span>
<span>(</span><span>seed: int, size: int, reward_type: <a title="colosseum.mdp.simple_grid.base.SimpleGridReward" href="#colosseum.mdp.simple_grid.base.SimpleGridReward">SimpleGridReward</a> = SimpleGridReward.XOR, n_starting_states: int = 1, optimal_mean_reward: float = 0.9, sub_optimal_mean_reward: float = 0.2, optimal_distribution: Union[Tuple[], scipy.stats._distn_infrastructure.rv_continuous] = None, sub_optimal_distribution: Union[Tuple[], scipy.stats._distn_infrastructure.rv_continuous] = None, other_distribution: Union[Tuple[], scipy.stats._distn_infrastructure.rv_continuous] = None, make_reward_stochastic=False, variance_multipliers: float = 1.0, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Abstract base class for Python RL environments.</p>
<p>Observations and valid actions are described with <code>Array</code> specs, defined in
the <code>specs</code> module.</p>
<p>instantiates the MDP.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>seed</code></strong> :&ensp;<code>int</code></dt>
<dd>is the random seed.</dd>
<dt><strong><code>randomize_actions</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>checks whether to apply a random mapping to the actions for each state. This avoids issues linked to
the possible bias of the agents to always take action zero at the beginning of the interactions.
By default, it is set to true.</dd>
<dt><strong><code>variance_multipliers</code></strong> :&ensp;<code>float</code>, optional</dt>
<dd>A constant that can be used to increase the variance of the reward distributions without changing their means.
The lower the value, the higher the variance. By default, it is set to 1.</dd>
<dt><strong><code>p_lazy</code></strong> :&ensp;<code>float</code>, optional</dt>
<dd>is the probability of an action not producing any effect on the MDP.
By default, it is set to zero.</dd>
<dt><strong><code>p_rand</code></strong> :&ensp;<code>float</code>, optional</dt>
<dd>is the probability of selecting an action at random instead of the one specified by the agent.
By default, it is set to zero.</dd>
<dt><strong><code>rewards_range</code></strong> :&ensp;<code>Tuple[float, float]</code>, optional</dt>
<dd>is the maximum value of the reward.
By default, it is set to the zero one interval.</dd>
<dt><strong><code>representation_mapping</code></strong> :&ensp;<code>RepresentationMapping</code></dt>
<dd>the representation mapping assigned to each state. By default, no representation mapping is used.</dd>
<dt><strong><code>hardness_reports_folder</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>is the path where the MDP looks for previously cached hardness reports.</dd>
<dt><strong><code>instantiate_mdp</code></strong> :&ensp;<code>bool</code></dt>
<dd>checks whether to immediately instantiate the MDP.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class SimpleGridMDP(BaseMDP, abc.ABC):
    @staticmethod
    def does_seed_change_MDP_structure() -&gt; bool:
        return True

    @staticmethod
    def _sample_parameters(
        n: int, is_episodic: bool, seed: int = None
    ) -&gt; List[Dict[str, Any]]:
        rng = np.random.RandomState(np.random.randint(10_000) if seed is None else seed)
        samples = []
        for _ in range(n):
            p_rand, p_lazy, _ = 0.9 * np.random.dirichlet([0.2, 0.2, 5])
            sample = dict(
                size=int(
                    (
                        1
                        + np.minimum((800 / (100 * np.random.random() + 35)), 25)
                        * (0.8 if is_episodic else 1)
                    )
                ),
                n_starting_states=rng.randint(1, 5),
                p_rand=p_rand,
                p_lazy=p_lazy,
                make_reward_stochastic=rng.choice([True, False]),
                variance_multipliers=2 * rng.random() + 0.005,
            )
            sample[&#34;p_rand&#34;] = None if sample[&#34;p_rand&#34;] &lt; 0.01 else sample[&#34;p_rand&#34;]
            sample[&#34;p_lazy&#34;] = None if sample[&#34;p_lazy&#34;] &lt; 0.01 else sample[&#34;p_lazy&#34;]

            if sample[&#34;make_reward_stochastic&#34;]:
                sample[&#34;sub_optimal_distribution&#34;] = beta(
                    sample[&#34;variance_multipliers&#34;],
                    sample[&#34;variance_multipliers&#34;] * (10 / 0.2 - 1),
                )
                sample[&#34;optimal_distribution&#34;] = beta(
                    sample[&#34;variance_multipliers&#34;],
                    sample[&#34;variance_multipliers&#34;] * (1 / 0.9 - 1),
                )
                sample[&#34;other_distribution&#34;] = beta(
                    sample[&#34;variance_multipliers&#34;],
                    sample[&#34;variance_multipliers&#34;] * (1 / 0.2 - 1),
                )
            else:
                sample[&#34;sub_optimal_distribution&#34;] = deterministic(0.0)
                sample[&#34;optimal_distribution&#34;] = deterministic(1.0)
                sample[&#34;other_distribution&#34;] = deterministic(0.5)
            samples.append(sample)
        return samples

    @staticmethod
    def get_node_class() -&gt; Type[&#34;NODE_TYPE&#34;]:
        return SimpleGridNode

    @property
    def n_actions(self) -&gt; int:
        return len(SimpleGridAction)

    def _get_next_nodes_parameters(
        self, node: &#34;NODE_TYPE&#34;, action: &#34;ACTION_TYPE&#34;
    ) -&gt; Tuple[Tuple[dict, float], ...]:
        if action == SimpleGridAction.UP:
            return ((dict(X=node.X, Y=min(node.Y + 1, self._size - 1)), 1.0),)
        if action == SimpleGridAction.RIGHT:
            return ((dict(X=min(node.X + 1, self._size - 1), Y=node.Y), 1.0),)
        if action == SimpleGridAction.DOWN:
            return ((dict(X=node.X, Y=max(node.Y - 1, 0)), 1.0),)
        if action == SimpleGridAction.LEFT:
            return ((dict(X=max(node.X - 1, 0), Y=node.Y), 1.0),)
        if action == SimpleGridAction.NO_OP:
            return ((dict(X=node.X, Y=node.Y), 1.0),)

    @staticmethod
    def _is_corner_loop(node, next_node, size):
        return (
            node.X == next_node.X
            and node.Y == next_node.Y
            and node.X in [0, size - 1]
            and node.Y in [0, size - 1]
        )

    def _get_reward_distribution(
        self, node: &#34;NODE_TYPE&#34;, action: &#34;ACTION_TYPE&#34;, next_node: &#34;NODE_TYPE&#34;
    ) -&gt; rv_continuous:
        # Corner nodes
        if SimpleGridMDP._is_corner_loop(node, next_node, self._size):
            if (
                (self._reward_type == SimpleGridReward.AND and (node.X and node.Y))
                or (
                    self._reward_type == SimpleGridReward.NAND
                    and not (node.X and node.Y)
                )
                or (self._reward_type == SimpleGridReward.OR and (node.X | node.Y))
                or (self._reward_type == SimpleGridReward.XOR and (node.X ^ node.Y))
            ):
                return self._optimal_distribution
            else:
                return self._sub_optimal_distribution
        else:
            return self._other_distribution

    def _calculate_starting_nodes(self):
        center = np.array(((self._size - 1) / 2, (self._size - 1) / 2))
        distances = np.empty((self._size, self._size))
        for x in range(self._size):
            for y in range(self._size):
                distances[x, y] = ((np.array((x, y)) - center) ** 2).sum()

        batch: list = np.array(np.where(distances == distances.min())).T.tolist()
        self._rng.shuffle(batch)
        while not np.all(distances == np.inf):
            distances[batch[0][0], batch[0][1]] = np.inf
            yield batch[0]
            batch.pop(0)
            if len(batch) == 0:
                batch: list = np.array(
                    np.where(distances == distances.min())
                ).T.tolist()

    def _get_starting_node_sampler(self) -&gt; NextStateSampler:
        starting_nodes_iter = self._calculate_starting_nodes()
        self.__possible_starting_nodes = [
            self.get_node_class()(*next(starting_nodes_iter))
            for _ in range((self._size - 1) ** 2)
        ]
        starting_nodes = self._possible_starting_nodes[: self._n_starting_states]
        self._rng.shuffle(starting_nodes)
        if len(starting_nodes) == 1:
            return NextStateSampler(next_nodes=starting_nodes)
        return NextStateSampler(
            next_nodes=starting_nodes,
            probs=[1 / self._n_starting_states for _ in range(self._n_starting_states)],
            seed=self._produce_random_seed(),
        )

    def _check_parameters_in_input(self):
        super(SimpleGridMDP, self)._check_parameters_in_input()

        assert self._n_starting_states &lt;= (self._size - 1) ** 2
        assert self._optimal_mean_reward - 0.1 &gt; self._sub_optimal_mean_reward

        dists = [
            self._sub_optimal_distribution,
            self._optimal_distribution,
            self._other_distribution,
        ]
        check_distributions(
            dists,
            self._make_reward_stochastic,
        )

    def _get_grid_representation(self, node: &#34;NODE_TYPE&#34;):
        grid = np.zeros((self._size, self._size), dtype=str)
        grid[:, :] = &#34; &#34;

        # Corner nodes
        if self._reward_type == SimpleGridReward.AND:
            grid[0, 0] = &#34;-&#34;
            grid[0, -1] = &#34;-&#34;
            grid[-1, 0] = &#34;-&#34;
            grid[-1, -1] = &#34;+&#34;
        elif self._reward_type == SimpleGridReward.NAND:
            grid[0, 0] = &#34;+&#34;
            grid[0, -1] = &#34;+&#34;
            grid[-1, 0] = &#34;+&#34;
            grid[-1, -1] = &#34;-&#34;
        elif self._reward_type == SimpleGridReward.OR:
            grid[0, 0] = &#34;-&#34;
            grid[0, -1] = &#34;+&#34;
            grid[-1, 0] = &#34;+&#34;
            grid[-1, -1] = &#34;+&#34;
        else:
            grid[0, 0] = &#34;-&#34;
            grid[0, -1] = &#34;+&#34;
            grid[-1, 0] = &#34;+&#34;
            grid[-1, -1] = &#34;-&#34;

        grid[node.Y, node.X] = &#34;A&#34;
        return grid[::-1, :]

    @property
    def _possible_starting_nodes(self) -&gt; List[&#34;NODE_TYPE&#34;]:
        return self.__possible_starting_nodes

    @property
    def parameters(self) -&gt; Dict[str, Any]:
        return {
            **super(SimpleGridMDP, self).parameters,
            **dict(
                size=self._size,
                reward_type=self._reward_type,
                n_starting_states=self._n_starting_states,
                optimal_mean_reward=self._optimal_mean_reward,
                sub_optimal_mean_reward=self._sub_optimal_mean_reward,
                optimal_distribution=self._optimal_distribution,
                sub_optimal_distribution=self._sub_optimal_distribution,
                other_distribution=self._other_distribution,
            ),
        }

    def __init__(
        self,
        seed: int,
        size: int,
        reward_type: SimpleGridReward = SimpleGridReward.XOR,
        n_starting_states: int = 1,
        optimal_mean_reward: float = 0.9,
        sub_optimal_mean_reward: float = 0.2,
        optimal_distribution: Union[Tuple, rv_continuous] = None,
        sub_optimal_distribution: Union[Tuple, rv_continuous] = None,
        other_distribution: Union[Tuple, rv_continuous] = None,
        make_reward_stochastic=False,
        variance_multipliers: float = 1.0,
        **kwargs,
    ):
        if type(sub_optimal_distribution) == tuple:
            sub_optimal_distribution = get_dist(
                sub_optimal_distribution[0], sub_optimal_distribution[1:]
            )
        if type(optimal_distribution) == tuple:
            optimal_distribution = get_dist(
                optimal_distribution[0], optimal_distribution[1:]
            )
        if type(other_distribution) == tuple:
            other_distribution = get_dist(other_distribution[0], other_distribution[1:])

        self._size = size
        self._reward_type = SimpleGridReward(reward_type)
        self._n_starting_states = n_starting_states
        self._optimal_mean_reward = optimal_mean_reward
        self._sub_optimal_mean_reward = sub_optimal_mean_reward
        dists = [
            sub_optimal_distribution,
            optimal_distribution,
            other_distribution,
        ]

        if dists.count(None) == 0:
            self._sub_optimal_distribution = sub_optimal_distribution
            self._optimal_distribution = optimal_distribution
            self._other_distribution = other_distribution
        else:
            if make_reward_stochastic:
                self._sub_optimal_distribution = beta(
                    variance_multipliers,
                    variance_multipliers * (10 / sub_optimal_mean_reward - 1),
                )
                self._optimal_distribution = beta(
                    variance_multipliers,
                    variance_multipliers * (1 / optimal_mean_reward - 1),
                )
                self._other_distribution = beta(
                    variance_multipliers,
                    variance_multipliers * (1 / sub_optimal_mean_reward - 1),
                )
            else:
                self._sub_optimal_distribution = deterministic(0.0)
                self._optimal_distribution = deterministic(1.0)
                self._other_distribution = deterministic(0.5)

        super(SimpleGridMDP, self).__init__(
            seed=seed,
            variance_multipliers=variance_multipliers,
            make_reward_stochastic=make_reward_stochastic,
            **kwargs,
        )</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="colosseum.mdp.base.BaseMDP" href="../base.html#colosseum.mdp.base.BaseMDP">BaseMDP</a></li>
<li>dm_env._environment.Environment</li>
<li>abc.ABC</li>
</ul>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="colosseum.mdp.simple_grid.finite_horizon.SimpleGridEpisodic" href="finite_horizon.html#colosseum.mdp.simple_grid.finite_horizon.SimpleGridEpisodic">SimpleGridEpisodic</a></li>
<li><a title="colosseum.mdp.simple_grid.infinite_horizon.SimpleGridContinuous" href="infinite_horizon.html#colosseum.mdp.simple_grid.infinite_horizon.SimpleGridContinuous">SimpleGridContinuous</a></li>
</ul>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="colosseum.mdp.base.BaseMDP" href="../base.html#colosseum.mdp.base.BaseMDP">BaseMDP</a></b></code>:
<ul class="hlist">
<li><code><a title="colosseum.mdp.base.BaseMDP.R" href="../base.html#colosseum.mdp.base.BaseMDP.R">R</a></code></li>
<li><code><a title="colosseum.mdp.base.BaseMDP.T" href="../base.html#colosseum.mdp.base.BaseMDP.T">T</a></code></li>
<li><code><a title="colosseum.mdp.base.BaseMDP.action_spec" href="../base.html#colosseum.mdp.base.BaseMDP.action_spec">action_spec</a></code></li>
<li><code><a title="colosseum.mdp.base.BaseMDP.communication_class" href="../base.html#colosseum.mdp.base.BaseMDP.communication_class">communication_class</a></code></li>
<li><code><a title="colosseum.mdp.base.BaseMDP.diameter" href="../base.html#colosseum.mdp.base.BaseMDP.diameter">diameter</a></code></li>
<li><code><a title="colosseum.mdp.base.BaseMDP.discounted_value_norm" href="../base.html#colosseum.mdp.base.BaseMDP.discounted_value_norm">discounted_value_norm</a></code></li>
<li><code><a title="colosseum.mdp.base.BaseMDP.does_seed_change_MDP_structure" href="../base.html#colosseum.mdp.base.BaseMDP.does_seed_change_MDP_structure">does_seed_change_MDP_structure</a></code></li>
<li><code><a title="colosseum.mdp.base.BaseMDP.get_grid_representation" href="../base.html#colosseum.mdp.base.BaseMDP.get_grid_representation">get_grid_representation</a></code></li>
<li><code><a title="colosseum.mdp.base.BaseMDP.get_info_class" href="../base.html#colosseum.mdp.base.BaseMDP.get_info_class">get_info_class</a></code></li>
<li><code><a title="colosseum.mdp.base.BaseMDP.get_measure_from_name" href="../base.html#colosseum.mdp.base.BaseMDP.get_measure_from_name">get_measure_from_name</a></code></li>
<li><code><a title="colosseum.mdp.base.BaseMDP.get_node_class" href="../base.html#colosseum.mdp.base.BaseMDP.get_node_class">get_node_class</a></code></li>
<li><code><a title="colosseum.mdp.base.BaseMDP.get_observation" href="../base.html#colosseum.mdp.base.BaseMDP.get_observation">get_observation</a></code></li>
<li><code><a title="colosseum.mdp.base.BaseMDP.get_optimal_policy" href="../base.html#colosseum.mdp.base.BaseMDP.get_optimal_policy">get_optimal_policy</a></code></li>
<li><code><a title="colosseum.mdp.base.BaseMDP.get_reward_distribution" href="../base.html#colosseum.mdp.base.BaseMDP.get_reward_distribution">get_reward_distribution</a></code></li>
<li><code><a title="colosseum.mdp.base.BaseMDP.get_transition_distributions" href="../base.html#colosseum.mdp.base.BaseMDP.get_transition_distributions">get_transition_distributions</a></code></li>
<li><code><a title="colosseum.mdp.base.BaseMDP.get_value_node_labels" href="../base.html#colosseum.mdp.base.BaseMDP.get_value_node_labels">get_value_node_labels</a></code></li>
<li><code><a title="colosseum.mdp.base.BaseMDP.get_visitation_counts" href="../base.html#colosseum.mdp.base.BaseMDP.get_visitation_counts">get_visitation_counts</a></code></li>
<li><code><a title="colosseum.mdp.base.BaseMDP.get_worst_policy" href="../base.html#colosseum.mdp.base.BaseMDP.get_worst_policy">get_worst_policy</a></code></li>
<li><code><a title="colosseum.mdp.base.BaseMDP.graph_layout" href="../base.html#colosseum.mdp.base.BaseMDP.graph_layout">graph_layout</a></code></li>
<li><code><a title="colosseum.mdp.base.BaseMDP.graph_metrics" href="../base.html#colosseum.mdp.base.BaseMDP.graph_metrics">graph_metrics</a></code></li>
<li><code><a title="colosseum.mdp.base.BaseMDP.hardness_report" href="../base.html#colosseum.mdp.base.BaseMDP.hardness_report">hardness_report</a></code></li>
<li><code><a title="colosseum.mdp.base.BaseMDP.hash" href="../base.html#colosseum.mdp.base.BaseMDP.hash">hash</a></code></li>
<li><code><a title="colosseum.mdp.base.BaseMDP.is_episodic" href="../base.html#colosseum.mdp.base.BaseMDP.is_episodic">is_episodic</a></code></li>
<li><code><a title="colosseum.mdp.base.BaseMDP.measures_of_hardness" href="../base.html#colosseum.mdp.base.BaseMDP.measures_of_hardness">measures_of_hardness</a></code></li>
<li><code><a title="colosseum.mdp.base.BaseMDP.n_actions" href="../base.html#colosseum.mdp.base.BaseMDP.n_actions">n_actions</a></code></li>
<li><code><a title="colosseum.mdp.base.BaseMDP.observation_spec" href="../base.html#colosseum.mdp.base.BaseMDP.observation_spec">observation_spec</a></code></li>
<li><code><a title="colosseum.mdp.base.BaseMDP.optimal_average_reward" href="../base.html#colosseum.mdp.base.BaseMDP.optimal_average_reward">optimal_average_reward</a></code></li>
<li><code><a title="colosseum.mdp.base.BaseMDP.optimal_average_rewards" href="../base.html#colosseum.mdp.base.BaseMDP.optimal_average_rewards">optimal_average_rewards</a></code></li>
<li><code><a title="colosseum.mdp.base.BaseMDP.optimal_markov_chain" href="../base.html#colosseum.mdp.base.BaseMDP.optimal_markov_chain">optimal_markov_chain</a></code></li>
<li><code><a title="colosseum.mdp.base.BaseMDP.optimal_stationary_distribution" href="../base.html#colosseum.mdp.base.BaseMDP.optimal_stationary_distribution">optimal_stationary_distribution</a></code></li>
<li><code><a title="colosseum.mdp.base.BaseMDP.optimal_transition_probabilities" href="../base.html#colosseum.mdp.base.BaseMDP.optimal_transition_probabilities">optimal_transition_probabilities</a></code></li>
<li><code><a title="colosseum.mdp.base.BaseMDP.optimal_value" href="../base.html#colosseum.mdp.base.BaseMDP.optimal_value">optimal_value</a></code></li>
<li><code><a title="colosseum.mdp.base.BaseMDP.parameters" href="../base.html#colosseum.mdp.base.BaseMDP.parameters">parameters</a></code></li>
<li><code><a title="colosseum.mdp.base.BaseMDP.random_average_reward" href="../base.html#colosseum.mdp.base.BaseMDP.random_average_reward">random_average_reward</a></code></li>
<li><code><a title="colosseum.mdp.base.BaseMDP.random_average_rewards" href="../base.html#colosseum.mdp.base.BaseMDP.random_average_rewards">random_average_rewards</a></code></li>
<li><code><a title="colosseum.mdp.base.BaseMDP.random_markov_chain" href="../base.html#colosseum.mdp.base.BaseMDP.random_markov_chain">random_markov_chain</a></code></li>
<li><code><a title="colosseum.mdp.base.BaseMDP.random_stationary_distribution" href="../base.html#colosseum.mdp.base.BaseMDP.random_stationary_distribution">random_stationary_distribution</a></code></li>
<li><code><a title="colosseum.mdp.base.BaseMDP.random_step" href="../base.html#colosseum.mdp.base.BaseMDP.random_step">random_step</a></code></li>
<li><code><a title="colosseum.mdp.base.BaseMDP.random_transition_probabilities" href="../base.html#colosseum.mdp.base.BaseMDP.random_transition_probabilities">random_transition_probabilities</a></code></li>
<li><code><a title="colosseum.mdp.base.BaseMDP.random_value" href="../base.html#colosseum.mdp.base.BaseMDP.random_value">random_value</a></code></li>
<li><code><a title="colosseum.mdp.base.BaseMDP.recurrent_nodes_set" href="../base.html#colosseum.mdp.base.BaseMDP.recurrent_nodes_set">recurrent_nodes_set</a></code></li>
<li><code><a title="colosseum.mdp.base.BaseMDP.reset" href="../base.html#colosseum.mdp.base.BaseMDP.reset">reset</a></code></li>
<li><code><a title="colosseum.mdp.base.BaseMDP.reset_visitation_counts" href="../base.html#colosseum.mdp.base.BaseMDP.reset_visitation_counts">reset_visitation_counts</a></code></li>
<li><code><a title="colosseum.mdp.base.BaseMDP.sample_parameters" href="../base.html#colosseum.mdp.base.BaseMDP.sample_parameters">sample_parameters</a></code></li>
<li><code><a title="colosseum.mdp.base.BaseMDP.sample_reward" href="../base.html#colosseum.mdp.base.BaseMDP.sample_reward">sample_reward</a></code></li>
<li><code><a title="colosseum.mdp.base.BaseMDP.step" href="../base.html#colosseum.mdp.base.BaseMDP.step">step</a></code></li>
<li><code><a title="colosseum.mdp.base.BaseMDP.sum_reciprocals_suboptimality_gaps" href="../base.html#colosseum.mdp.base.BaseMDP.sum_reciprocals_suboptimality_gaps">sum_reciprocals_suboptimality_gaps</a></code></li>
<li><code><a title="colosseum.mdp.base.BaseMDP.summary" href="../base.html#colosseum.mdp.base.BaseMDP.summary">summary</a></code></li>
<li><code><a title="colosseum.mdp.base.BaseMDP.transition_matrix_and_rewards" href="../base.html#colosseum.mdp.base.BaseMDP.transition_matrix_and_rewards">transition_matrix_and_rewards</a></code></li>
<li><code><a title="colosseum.mdp.base.BaseMDP.undiscounted_value_norm" href="../base.html#colosseum.mdp.base.BaseMDP.undiscounted_value_norm">undiscounted_value_norm</a></code></li>
<li><code><a title="colosseum.mdp.base.BaseMDP.value_norm" href="../base.html#colosseum.mdp.base.BaseMDP.value_norm">value_norm</a></code></li>
<li><code><a title="colosseum.mdp.base.BaseMDP.worst_average_reward" href="../base.html#colosseum.mdp.base.BaseMDP.worst_average_reward">worst_average_reward</a></code></li>
<li><code><a title="colosseum.mdp.base.BaseMDP.worst_average_rewards" href="../base.html#colosseum.mdp.base.BaseMDP.worst_average_rewards">worst_average_rewards</a></code></li>
<li><code><a title="colosseum.mdp.base.BaseMDP.worst_markov_chain" href="../base.html#colosseum.mdp.base.BaseMDP.worst_markov_chain">worst_markov_chain</a></code></li>
<li><code><a title="colosseum.mdp.base.BaseMDP.worst_stationary_distribution" href="../base.html#colosseum.mdp.base.BaseMDP.worst_stationary_distribution">worst_stationary_distribution</a></code></li>
<li><code><a title="colosseum.mdp.base.BaseMDP.worst_transition_probabilities" href="../base.html#colosseum.mdp.base.BaseMDP.worst_transition_probabilities">worst_transition_probabilities</a></code></li>
<li><code><a title="colosseum.mdp.base.BaseMDP.worst_value" href="../base.html#colosseum.mdp.base.BaseMDP.worst_value">worst_value</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="colosseum.mdp.simple_grid.base.SimpleGridNode"><code class="flex name class">
<span>class <span class="ident">SimpleGridNode</span></span>
<span>(</span><span>X: int, Y: int)</span>
</code></dt>
<dd>
<div class="desc"><p>SimpleGridNode(X: int, Y: int)</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class SimpleGridNode:
    X: int
    Y: int

    def __str__(self):
        return f&#34;X={self.X},Y={self.Y}&#34;

    def __iter__(self):
        return iter((self.X, self.Y))</code></pre>
</details>
<h3>Class variables</h3>
<dl>
<dt id="colosseum.mdp.simple_grid.base.SimpleGridNode.X"><code class="name">var <span class="ident">X</span> : int</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="colosseum.mdp.simple_grid.base.SimpleGridNode.Y"><code class="name">var <span class="ident">Y</span> : int</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
</dd>
<dt id="colosseum.mdp.simple_grid.base.SimpleGridReward"><code class="flex name class">
<span>class <span class="ident">SimpleGridReward</span></span>
<span>(</span><span>value, names=None, *, module=None, qualname=None, type=None, start=1)</span>
</code></dt>
<dd>
<div class="desc"><p>The reward types available in the SimpleGrid MDP.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class SimpleGridReward(IntEnum):
    &#34;&#34;&#34;The reward types available in the SimpleGrid MDP.&#34;&#34;&#34;

    AND = 0
    NAND = 1
    OR = 2
    XOR = 3</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>enum.IntEnum</li>
<li>builtins.int</li>
<li>enum.Enum</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="colosseum.mdp.simple_grid.base.SimpleGridReward.AND"><code class="name">var <span class="ident">AND</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="colosseum.mdp.simple_grid.base.SimpleGridReward.NAND"><code class="name">var <span class="ident">NAND</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="colosseum.mdp.simple_grid.base.SimpleGridReward.OR"><code class="name">var <span class="ident">OR</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="colosseum.mdp.simple_grid.base.SimpleGridReward.XOR"><code class="name">var <span class="ident">XOR</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="colosseum.mdp.simple_grid" href="index.html">colosseum.mdp.simple_grid</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="colosseum.mdp.simple_grid.base.SimpleGridAction" href="#colosseum.mdp.simple_grid.base.SimpleGridAction">SimpleGridAction</a></code></h4>
<ul class="">
<li><code><a title="colosseum.mdp.simple_grid.base.SimpleGridAction.DOWN" href="#colosseum.mdp.simple_grid.base.SimpleGridAction.DOWN">DOWN</a></code></li>
<li><code><a title="colosseum.mdp.simple_grid.base.SimpleGridAction.LEFT" href="#colosseum.mdp.simple_grid.base.SimpleGridAction.LEFT">LEFT</a></code></li>
<li><code><a title="colosseum.mdp.simple_grid.base.SimpleGridAction.NO_OP" href="#colosseum.mdp.simple_grid.base.SimpleGridAction.NO_OP">NO_OP</a></code></li>
<li><code><a title="colosseum.mdp.simple_grid.base.SimpleGridAction.RIGHT" href="#colosseum.mdp.simple_grid.base.SimpleGridAction.RIGHT">RIGHT</a></code></li>
<li><code><a title="colosseum.mdp.simple_grid.base.SimpleGridAction.UP" href="#colosseum.mdp.simple_grid.base.SimpleGridAction.UP">UP</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="colosseum.mdp.simple_grid.base.SimpleGridMDP" href="#colosseum.mdp.simple_grid.base.SimpleGridMDP">SimpleGridMDP</a></code></h4>
</li>
<li>
<h4><code><a title="colosseum.mdp.simple_grid.base.SimpleGridNode" href="#colosseum.mdp.simple_grid.base.SimpleGridNode">SimpleGridNode</a></code></h4>
<ul class="">
<li><code><a title="colosseum.mdp.simple_grid.base.SimpleGridNode.X" href="#colosseum.mdp.simple_grid.base.SimpleGridNode.X">X</a></code></li>
<li><code><a title="colosseum.mdp.simple_grid.base.SimpleGridNode.Y" href="#colosseum.mdp.simple_grid.base.SimpleGridNode.Y">Y</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="colosseum.mdp.simple_grid.base.SimpleGridReward" href="#colosseum.mdp.simple_grid.base.SimpleGridReward">SimpleGridReward</a></code></h4>
<ul class="">
<li><code><a title="colosseum.mdp.simple_grid.base.SimpleGridReward.AND" href="#colosseum.mdp.simple_grid.base.SimpleGridReward.AND">AND</a></code></li>
<li><code><a title="colosseum.mdp.simple_grid.base.SimpleGridReward.NAND" href="#colosseum.mdp.simple_grid.base.SimpleGridReward.NAND">NAND</a></code></li>
<li><code><a title="colosseum.mdp.simple_grid.base.SimpleGridReward.OR" href="#colosseum.mdp.simple_grid.base.SimpleGridReward.OR">OR</a></code></li>
<li><code><a title="colosseum.mdp.simple_grid.base.SimpleGridReward.XOR" href="#colosseum.mdp.simple_grid.base.SimpleGridReward.XOR">XOR</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>