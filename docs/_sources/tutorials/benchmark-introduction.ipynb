{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "015301e8",
   "metadata": {},
   "source": [
    "# Colosseum benchmark\n",
    "\n",
    "`````{margin}\n",
    "````{dropdown} Necessary imports\n",
    "```{code-block} python\n",
    "import seedir\n",
    "\n",
    "from colosseum.benchmark import ColosseumDefaultBenchmark\n",
    "from colosseum.benchmark.utils import instantiate_benchmark_folder\n",
    "```\n",
    "````\n",
    "`````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fd5f8e7",
   "metadata": {
    "tags": [
     "remove-input",
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from glob import glob\n",
    "\n",
    "import seedir\n",
    "\n",
    "from colosseum.benchmark import ColosseumDefaultBenchmark\n",
    "from colosseum.benchmark.utils import instantiate_benchmark_folder\n",
    "\n",
    "def print_benchmark_configurations():\n",
    "    bdir = glob(\"benchmark_*\")[0]\n",
    "    print(\"Default experiment configuration in the 'experiment_config.yml' files.\")\n",
    "    with open(bdir + os.sep + \"experiment_config.yml\") as f:\n",
    "        print(\"\".join(map(lambda x: \"\\t\" + x, sorted(f.readlines(), key=len))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9602e1eb",
   "metadata": {},
   "source": [
    "This tutorial introduces the default {{col}} benchmark, which targets the four most widely studies setting of {{rl}}: episodic ergodic, episodic communicating, continuous ergodic, and continuous communicating.\n",
    "Note that the continuous setting is also known as infinite horizon.\n",
    "\n",
    "As explained in the {{paper}}, the environment selections is the result of the theoretical analysis presented in the paper, which has been validated through an empirical study of the behaviour of the hardness measures.\n",
    "Concretely, for each of the aforementioned settings, $20$ environments have been selected to be as diverse as possible with respect to the diameter and the environmental value norm, which act as proxies for the visitation complexity and the estimation complexity.\n",
    "The candidate environments have been sampled from a set of parameters such that their diameter is less than $100$ and the environmental value norm is less than $3.5$ to guarantee a sufficient challenge while limiting the scale of the environments.\n",
    "\n",
    "````` {margin}\n",
    "```` {admonition} MDP families APIs\n",
    "<a href=\"../pdoc_files/colosseum/mdp/deep_sea/base.html\">``DeepSea``</a>,\n",
    "<a href=\"../pdoc_files/colosseum/mdp/frozen_lake/base.html\">``FrozenLake``</a>,\n",
    "<a href=\"../pdoc_files/colosseum/mdp/minigrid_empty/base.html\">``MiniGridEmpty``</a>,\n",
    "<a href=\"../pdoc_files/colosseum/mdp/minigrid_rooms/base.html\">``MiniGridRooms``</a>,\n",
    "<a href=\"../pdoc_files/colosseum/mdp/river_swim/base.html\">``RiverSwim``</a>,\n",
    "<a href=\"../pdoc_files/colosseum/mdp/simple_grid/base.html\">``SimpleGrid``</a>, and\n",
    "<a href=\"../pdoc_files/colosseum/mdp/taxi/base.html\">``Taxi``</a>.\n",
    "````\n",
    "`````\n",
    "\n",
    "## The {{col}} benchmark MDPs\n",
    "\n",
    "The tables below report the environments in the benchmark along with their parameters.\n",
    "We briefly describe the parameters that are common to all environment below, and we refer to the API of the agent classes for\n",
    "specific parameters.\n",
    "\n",
    "The `size` parameter controls the number of states,\n",
    "the `make_reward_stochastic` parameter checks whether the rewards are stochastic,\n",
    "the `p_lazy` parameter is the probability that an MDP stays in the same state instead of executing the action selected by an agent, and\n",
    "the `p_rand` parameter is the probability that an MDP executes a random action instead of the action selected by an agent.\n",
    "\n",
    "\n",
    "### Episodic ergodic\n",
    "\n",
    "`````{div} full-width\n",
    "````{tab-set}\n",
    "```{tab-item} DeepSea\n",
    "1. DeepSea(size=10, p_rand=0.4, make_reward_stochastic=False)\n",
    "2. DeepSea(size=13, p_rand=0.3, make_reward_stochastic=True)\n",
    "```\n",
    "```{tab-item} FrozenLake\n",
    "1. FrozenLake(size=4, make_reward_stochastic=True, p_lazy=0.03, p_frozen=0.98, p_rand=0.001)\n",
    "```\n",
    "```{tab-item} MiniGridEmpty\n",
    "1. MiniGridEmpty(size=10, make_reward_stochastic=False, p_lazy=None, p_rand=0.05, n_starting_states=3)\n",
    "2. MiniGridEmpty(size=10, make_reward_stochastic=True, p_lazy=None, p_rand=0.3, n_starting_states=3)\n",
    "3. MiniGridEmpty(size=10, make_reward_stochastic=False, p_lazy=0.05, p_rand=0.2, n_starting_states=3)\n",
    "4. MiniGridEmpty(size=8, make_reward_stochastic=False, p_lazy=None, p_rand=0.3, n_starting_states=3)\n",
    "5. MiniGridEmpty(size=8, make_reward_stochastic=True, p_lazy=0.02, p_rand=0.4, n_starting_states=3)\n",
    "6. MiniGridEmpty(size=6, make_reward_stochastic=True, p_lazy=0.1, p_rand=0.05, n_starting_states=3)\n",
    "7. MiniGridEmpty(size=4, make_reward_stochastic=False, p_lazy=0.1, p_rand=0.4, n_starting_states=3)\n",
    "```\n",
    "```{tab-item} MiniGridRooms\n",
    "1. MiniGridRooms(make_reward_stochastic=True, room_size=3, n_rooms=4, p_rand=0.001, p_lazy=None)\n",
    "2. MiniGridRooms(make_reward_stochastic=True, room_size=3, n_rooms=9, p_rand=0.1, p_lazy=0.01)\n",
    "3. MiniGridRooms(make_reward_stochastic=True, room_size=4, n_rooms=4, p_rand=0.1, p_lazy=0.01)\n",
    "```\n",
    "```{tab-item} RiverSwim\n",
    "1. RiverSwim(make_reward_stochastic=True, size=5, p_lazy=0.1, p_rand=0.01, sub_optimal_distribution=(\"beta\",(2.4, 24.0)), optimal_distribution=(\"beta\",(0.01, 0.11)), other_distribution=(\"beta\",(2.4, 249.0)))\n",
    "2. RiverSwim(make_reward_stochastic=True, size=30, p_lazy=0.01, p_rand=0.01, sub_optimal_distribution=(\"beta\",(14.9, 149.0)), optimal_distribution=(\"beta\",(0.01, 0.11)), other_distribution=(\"beta\",(14.9, 1499.0)))\n",
    "```\n",
    "```{tab-item} SimpleGrid\n",
    "1. SimpleGrid(reward_type=3, size=10, make_reward_stochastic=True, p_lazy=0.2, p_rand=0.01)\n",
    "2. SimpleGrid(reward_type=3, size=16, make_reward_stochastic=True, p_lazy=0.2, p_rand=0.2)\n",
    "3. SimpleGrid(reward_type=3, size=16, make_reward_stochastic=False, p_lazy=0.01, p_rand=0.2)\n",
    "```\n",
    "```{tab-item} Taxi\n",
    "1. Taxi(make_reward_stochastic=True, p_lazy=0.001, size=4, length=1, width=1, space=1, n_locations=3, p_rand=0.01, default_r=(\"beta\",(0.8, 20.0)), successfully_delivery_r=(\"beta\",(1.0, 0.1)), failure_delivery_r=(\"beta\",(0.8, 50.0)))\n",
    "2. Taxi(make_reward_stochastic=True, p_lazy=0.01, size=4, length=1, width=1, space=1, n_locations=3, p_rand=0.2, default_r=(\"beta\",(0.8, 6.0)), successfully_delivery_r=(\"beta\",(1.0, 0.1)), failure_delivery_r=(\"beta\",(0.8, 40.0)))\n",
    "```\n",
    "````\n",
    "`````\n",
    "\n",
    "### Episodic communicating\n",
    "\n",
    "\n",
    "`````{div} full-width\n",
    "````{tab-set}\n",
    "```{tab-item} DeepSea\n",
    "1. DeepSea(size=5, p_rand=None, make_reward_stochastic=True)\n",
    "2. DeepSea(size=25, p_rand=None, make_reward_stochastic=True)\n",
    "```\n",
    "```{tab-item} FrozenLake\n",
    "1. FrozenLake(size=3, make_reward_stochastic=True, p_lazy=None, p_frozen=0.9, p_rand=None)\n",
    "```\n",
    "```{tab-item} MiniGridEmpty\n",
    "1. MiniGridEmpty(size=6, make_reward_stochastic=True, p_lazy=None, p_rand=None, n_starting_states=3)\n",
    "2. MiniGridEmpty(size=6, make_reward_stochastic=True, p_lazy=0.35, p_rand=None, n_starting_states=5)\n",
    "3. MiniGridEmpty(size=6, make_reward_stochastic=True, p_lazy=0.25, p_rand=0.1, n_starting_states=3)\n",
    "4. MiniGridEmpty(size=10, make_reward_stochastic=False, p_lazy=0.1, p_rand=None, n_starting_states=5)\n",
    "5. MiniGridEmpty(size=10, make_reward_stochastic=False, p_lazy=0.15, p_rand=0.1, n_starting_states=3)\n",
    "```\n",
    "```{tab-item} MiniGridRooms\n",
    "1. MiniGridRooms(make_reward_stochastic=True, room_size=4, n_rooms=4, p_rand=None, p_lazy=None)\n",
    "2. MiniGridRooms(make_reward_stochastic=False, room_size=3, n_rooms=9, p_rand=None, p_lazy=0.05)\n",
    "3. MiniGridRooms(make_reward_stochastic=False, room_size=3, n_rooms=9, p_rand=None, p_lazy=0.1)\n",
    "4. MiniGridRooms(make_reward_stochastic=False, room_size=3, n_rooms=4, p_rand=None, p_lazy=0.15)\n",
    "```\n",
    "```{tab-item} RiverSwim\n",
    "1. RiverSwim(make_reward_stochastic=True, size=25, p_lazy=0.05, p_rand=None, sub_optimal_distribution=(\"beta\",(12.4, 124.0)), optimal_distribution=(\"beta\",(0.01, 0.11)), other_distribution=(\"beta\",(12.4, 1249.0)))\n",
    "2. RiverSwim(make_reward_stochastic=False, size=40, p_lazy=None, p_rand=None, sub_optimal_distribution=None, optimal_distribution=None, other_distribution=None)\n",
    "```\n",
    "```{tab-item} SimpleGrid\n",
    "1. SimpleGrid(size=10, make_reward_stochastic=True, p_lazy=0.5)\n",
    "2. SimpleGrid(size=13, make_reward_stochastic=True, p_lazy=0.4)\n",
    "3. SimpleGrid(size=13, make_reward_stochastic=False, p_lazy=None)\n",
    "4. SimpleGrid(size=20, make_reward_stochastic=True, p_lazy=0.4)\n",
    "```\n",
    "```{tab-item} Taxi\n",
    "1. Taxi(make_reward_stochastic=True, p_lazy=0.01, size=4, length=1, width=1, space=1, n_locations=3, p_rand=None, default_r=(\"beta\",(0.7, 30.0)), successfully_delivery_r=(\"beta\",(0.4, 0.1)), failure_delivery_r=(\"beta\",(0.8, 50.0)))\n",
    "2. Taxi(make_reward_stochastic=True, p_lazy=0.2, size=5, length=1, width=1, space=1, n_locations=3, p_rand=None, default_r=(\"beta\",(0.7, 30.0)), successfully_delivery_r=(\"beta\", (0.4, 0.1)), failure_delivery_r=(\"beta\",(0.8, 50.0)))\n",
    "```\n",
    "````\n",
    "`````\n",
    "\n",
    "\n",
    "### Continuous ergodic\n",
    "\n",
    "\n",
    "`````{div} full-width\n",
    "````{tab-set}\n",
    "```{tab-item} DeepSea\n",
    "1. DeepSea(size=20, p_rand=0.1, make_reward_stochastic=False)\n",
    "```\n",
    "```{tab-item} FrozenLake\n",
    "1. FrozenLake(size=5, make_reward_stochastic=True, p_lazy=0.01, p_frozen=0.95, p_rand=0.05)\n",
    "```\n",
    "```{tab-item} MiniGridEmpty\n",
    "1. MiniGridEmpty(size=12, make_reward_stochastic=True, p_lazy=0.05, p_rand=0.495, n_starting_states=3)\n",
    "2. MiniGridEmpty(size=12, make_reward_stochastic=True, p_lazy=0.1, p_rand=0.395, n_starting_states=3)\n",
    "3. MiniGridEmpty(size=10, make_reward_stochastic=False, p_lazy=0.02, p_rand=0.7, n_starting_states=3)\n",
    "4. MiniGridEmpty(size=14, make_reward_stochastic=True, p_lazy=0.02, p_rand=0.6, n_starting_states=3)\n",
    "5. MiniGridEmpty(size=10, make_reward_stochastic=True, p_lazy=0.1, p_rand=0.21, n_starting_states=3, optimal_distribution=(\"beta\",(1.0, 0.11)), other_distribution=(\"beta\",(1.0, 4.0)))\n",
    "6. MiniGridEmpty(size=14, make_reward_stochastic=True, p_lazy=0.02, p_rand=0.4, n_starting_states=3, optimal_distribution=(\"beta\",(0.5, 0.11)), other_distribution=(\"beta\",(1.5, 4.0)))\n",
    "7. MiniGridEmpty(size=14, make_reward_stochastic=True, p_lazy=0.05, p_rand=0.31, n_starting_states=3, optimal_distribution=(\"beta\",(1.0, 0.11)), other_distribution=(\"beta\",(1.0, 4.0)))\n",
    "8. MiniGridEmpty(size=14, make_reward_stochastic=True, p_lazy=0.1, p_rand=0.6, n_starting_states=3, optimal_distribution=(\"beta\",(0.3, 0.11)), other_distribution=(\"beta\",(2.0, 4.0)))\n",
    "```\n",
    "```{tab-item} MiniGridRooms\n",
    "1. MiniGridRooms(make_reward_stochastic=True, room_size=3, n_rooms=16, p_rand=0.1, p_lazy=0.4)\n",
    "2. MiniGridRooms(make_reward_stochastic=False, room_size=5, n_rooms=9, p_rand=0.3, p_lazy=0.4)\n",
    "```\n",
    "```{tab-item} RiverSwim\n",
    "1. RiverSwim(make_reward_stochastic=False, size=30, p_lazy=0.1, p_rand=0.2)\n",
    "2. RiverSwim(make_reward_stochastic=True, size=50, p_lazy=0.1, p_rand=0.1)\n",
    "3. RiverSwim(make_reward_stochastic=True, size=80, p_lazy=0.001, p_rand=0.2)\n",
    "4. RiverSwim(make_reward_stochastic=False, size=80, p_lazy=0.1, p_rand=0.01)\n",
    "```\n",
    "```{tab-item} SimpleGrid\n",
    "1. SimpleGrid(size=15, make_reward_stochastic=True, p_lazy=0.4, p_rand=0.4)\n",
    "2. SimpleGrid(size=10, make_reward_stochastic=False, p_lazy=0.2, sub_optimal_distribution=None, optimal_distribution=None, other_distribution=None, p_rand=0.01)\n",
    "3. SimpleGrid(size=20, make_reward_stochastic=False, p_lazy=0.1, sub_optimal_distribution=None, optimal_distribution=None, other_distribution=None, p_rand=0.1)\n",
    "```\n",
    "```{tab-item} Taxi\n",
    "1. Taxi(make_reward_stochastic=True, p_lazy=0.01, size=4, length=1, width=1, space=1, n_locations=3, p_rand=0.1, default_r=(\"beta\",(0.8, 20.0)), successfully_delivery_r=(\"beta\",(1.0, 0.1)), failure_delivery_r=(\"beta\",(0.8, 50.0)))\n",
    "```\n",
    "````\n",
    "`````\n",
    "\n",
    "\n",
    "### Continuous communicating\n",
    "\n",
    "\n",
    "`````{div} full-width\n",
    "````{tab-set}\n",
    "```{tab-item} DeepSea\n",
    "1. DeepSea(size=40, p_rand=None, make_reward_stochastic=True)\n",
    "2. DeepSea(size=40, p_rand=None, make_reward_stochastic=False)\n",
    "3. DeepSea(size=35, p_rand=None, make_reward_stochastic=True)\n",
    "```\n",
    "```{tab-item} FrozenLake\n",
    "1. FrozenLake(size=4, make_reward_stochastic=True, p_lazy=0.01, p_frozen=0.95, p_rand=None)\n",
    "2. FrozenLake(size=5, make_reward_stochastic=True, p_lazy=0.35, p_frozen=0.9, p_rand=None)\n",
    "```\n",
    "```{tab-item} MiniGridEmpty\n",
    "1. MiniGridEmpty(size=12, make_reward_stochastic=True, p_lazy=0.25, p_rand=None, n_starting_states=3, optimal_distribution=(\"beta\",(1.0, 0.11)), other_distribution=(\"beta\",(1.0, 4.0)))\n",
    "2. MiniGridEmpty(size=12, make_reward_stochastic=False, p_lazy=0.3, p_rand=None, n_starting_states=3, optimal_distribution=None, other_distribution=None)\n",
    "3. MiniGridEmpty(size=8, make_reward_stochastic=False, p_lazy=0.3, p_rand=None, n_starting_states=3, optimal_distribution=None, other_distribution=None)\n",
    "4. MiniGridEmpty(size=8, make_reward_stochastic=True, p_lazy=0.7, p_rand=None, n_starting_states=3, optimal_distribution=(\"beta\",(1.0, 0.11)), other_distribution=(\"beta\",(1.0, 4.0)))\n",
    "5. MiniGridEmpty(size=12, make_reward_stochastic=True, p_lazy=0.7, p_rand=None, n_starting_states=3, optimal_distribution=(\"beta\",(1.0, 0.11)), other_distribution=(\"beta\",(1.0, 4.0)))\n",
    "```\n",
    "```{tab-item} MiniGridRooms\n",
    "1. MiniGridRooms(make_reward_stochastic=True, room_size=5, n_rooms=9, p_rand=None, p_lazy=0.3)\n",
    "2. MiniGridRooms(make_reward_stochastic=True, room_size=3, n_rooms=9, p_rand=None, p_lazy=0.5)\n",
    "3. MiniGridRooms(make_reward_stochastic=True, room_size=5, n_rooms=9, p_rand=None, p_lazy=0.5)\n",
    "```\n",
    "```{tab-item} RiverSwim\n",
    "1. RiverSwim(make_reward_stochastic=True, size=25, p_lazy=0.1, p_rand=None)\n",
    "2. RiverSwim(make_reward_stochastic=True, size=90, p_lazy=0.03, p_rand=None)\n",
    "```\n",
    "```{tab-item} SimpleGrid\n",
    "1. SimpleGrid(size=15, make_reward_stochastic=True, p_lazy=0.2, p_rand=None, sub_optimal_distribution=(\"beta\",(0.3, 49.0)), optimal_distribution=(\"beta\",(2.0, 0.11)), other_distribution=(\"beta\",(0.3, 4.0)))\n",
    "2. SimpleGrid(size=16, make_reward_stochastic=False, p_lazy=0.065, p_rand=None, sub_optimal_distribution=None, optimal_distribution=None, other_distribution=None)\n",
    "3. SimpleGrid(size=25, make_reward_stochastic=True, p_lazy=0.1, p_rand=None, sub_optimal_distribution=(\"beta\",(0.3, 49.0)), optimal_distribution=(\"beta\",(2.0, 0.11)), other_distribution=(\"beta\",(0.3, 4.0)))\n",
    "4. SimpleGrid(size=25, make_reward_stochastic=False, p_lazy=0.3, p_rand=None, sub_optimal_distribution=None, optimal_distribution=None, other_distribution=None)\n",
    "```\n",
    "```{tab-item} Taxi\n",
    "1. Taxi(make_reward_stochastic=True, p_lazy=0.01, size=4, length=1, width=1, space=1, n_locations=3, p_rand=None, default_r=(\"beta\",(0.7, 30.0)), successfully_delivery_r=(\"beta\",(0.4, 0.1)), failure_delivery_r=(\"beta\",(0.8, 50.0)))\n",
    "```\n",
    "````\n",
    "`````\n",
    "\n",
    "### {{col}} environments hardness\n",
    "\n",
    "In order to show that the environments in the benchmark are effectively diverse according to the hardness measures,\n",
    "{numref}`Figure %s<hardness_space>` places the benchmark environments according to their diameter and value norm.\n",
    "\n",
    "```{figure} ../../images/space_of_hardness.svg\n",
    ":name: hardness_space\n",
    "\n",
    "Positions in measure of hardness space of the MDPs in the benchmark.\n",
    "```\n",
    "\n",
    "## Instantiate the {{col}} benchmark\n",
    "\n",
    "A benchmark in {{col}} can be instantiated using the [`ColosseumBenchmark`](../pdoc_files/colosseum/benchmark/benchmark.html#ColosseumBenchmark)\n",
    "class.\n",
    "A `ColosseumBenchmark` object contains the parameters of the MDP and an [`ExperimentConfig`](../pdoc_files/colosseum/experiment/config.html#ExperimentConfig), which regulates the agent/MDP interactions.\n",
    "The default benchmark can be accesses through the [`ColosseumDefaultBenchmark`](../pdoc_files/colosseum/benchmark/benchmark.html#ColosseumDefaultBenchmark)\n",
    "enumeration, which also allow to retrieve the benchmark as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d605acd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📁 benchmark_er/\n",
      "├─📁 mdp_configs/\n",
      "│ ├─📄 MiniGridRoomsEpisodic.gin\n",
      "│ ├─📄 DeepSeaEpisodic.gin\n",
      "│ ├─📄 SimpleGridEpisodic.gin\n",
      "│ ├─📄 MiniGridEmptyEpisodic.gin\n",
      "│ ├─📄 TaxiEpisodic.gin\n",
      "│ ├─📄 RiverSwimEpisodic.gin\n",
      "│ └─📄 FrozenLakeEpisodic.gin\n",
      "└─📄 experiment_config.yml\n",
      "📁 benchmark_ec/\n",
      "├─📁 mdp_configs/\n",
      "│ ├─📄 MiniGridRoomsEpisodic.gin\n",
      "│ ├─📄 DeepSeaEpisodic.gin\n",
      "│ ├─📄 SimpleGridEpisodic.gin\n",
      "│ ├─📄 MiniGridEmptyEpisodic.gin\n",
      "│ ├─📄 TaxiEpisodic.gin\n",
      "│ ├─📄 RiverSwimEpisodic.gin\n",
      "│ └─📄 FrozenLakeEpisodic.gin\n",
      "└─📄 experiment_config.yml\n",
      "📁 benchmark_ce/\n",
      "├─📁 mdp_configs/\n",
      "│ ├─📄 MiniGridEmptyContinuous.gin\n",
      "│ ├─📄 TaxiContinuous.gin\n",
      "│ ├─📄 DeepSeaContinuous.gin\n",
      "│ ├─📄 MiniGridRoomsContinuous.gin\n",
      "│ ├─📄 RiverSwimContinuous.gin\n",
      "│ ├─📄 SimpleGridContinuous.gin\n",
      "│ └─📄 FrozenLakeContinuous.gin\n",
      "└─📄 experiment_config.yml\n",
      "📁 benchmark_cc/\n",
      "├─📁 mdp_configs/\n",
      "│ ├─📄 MiniGridEmptyContinuous.gin\n",
      "│ ├─📄 TaxiContinuous.gin\n",
      "│ ├─📄 DeepSeaContinuous.gin\n",
      "│ ├─📄 MiniGridRoomsContinuous.gin\n",
      "│ ├─📄 RiverSwimContinuous.gin\n",
      "│ ├─📄 SimpleGridContinuous.gin\n",
      "│ └─📄 FrozenLakeContinuous.gin\n",
      "└─📄 experiment_config.yml\n",
      "----------------------------------------------------------------------\n",
      "Default experiment configuration in the 'experiment_config.yml' files.\n",
      "\tn_seeds: 20\n",
      "\tn_steps: 500000\n",
      "\tmax_interaction_time_s: 600\n",
      "\tlog_performance_indicators_every: 100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Locally instantiate the episodic ergodic benchmark with folder name \"benchmark_er\"\n",
    "instantiate_benchmark_folder(\n",
    "    ColosseumDefaultBenchmark.EPISODIC_ERGODIC.get_benchmark(), \"benchmark_er\"\n",
    ")\n",
    "\n",
    "# Locally instantiate the episodic communicating benchmark with folder name \"benchmark_ec\"\n",
    "instantiate_benchmark_folder(\n",
    "    ColosseumDefaultBenchmark.EPISODIC_COMMUNICATING.get_benchmark(), \"benchmark_ec\"\n",
    ")\n",
    "\n",
    "# Locally instantiate the continuous ergodic benchmark with folder name \"benchmark_ce\"\n",
    "instantiate_benchmark_folder(\n",
    "    ColosseumDefaultBenchmark.CONTINUOUS_ERGODIC.get_benchmark(), \"benchmark_ce\"\n",
    ")\n",
    "\n",
    "# Locally instantiate the continuous communicating benchmark with folder name \"benchmark_cc\"\n",
    "instantiate_benchmark_folder(\n",
    "    ColosseumDefaultBenchmark.CONTINUOUS_COMMUNICATING.get_benchmark(), \"benchmark_cc\"\n",
    ")\n",
    "\n",
    "# Print the folder structure of the benchmark\n",
    "for bdir in glob(\"benchmark_*\"):\n",
    "    seedir.seedir(bdir, style=\"emoji\")\n",
    "print(\"-\" * 70)\n",
    "# Print the benchmark configurations\n",
    "print_benchmark_configurations()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6373402b",
   "metadata": {},
   "source": [
    "The ```mdp_configs``` folder contains the Gin files with the configurations of the MDPs that were previously presented.  \n",
    "The ```experiment_config.yml``` file contains the default `ExperimentConfig`, which prescribes to run the agent/MDP interaction for a total of $500\\ 000$ time steps with a maximum interaction time of $10$ minutes for $20$ seeds.\n",
    "The performance indicators are computed every $100$ interactions to keep their computational cost low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdaccfda",
   "metadata": {
    "tags": [
     "remove-input",
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "shutil.rmtree(\"benchmark_er\")\n",
    "shutil.rmtree(\"benchmark_ec\")\n",
    "shutil.rmtree(\"benchmark_cc\")\n",
    "shutil.rmtree(\"benchmark_ce\")\n",
    "shutil.rmtree(\"tmp\", ignore_errors=True)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "md:myst",
   "text_representation": {
    "extension": ".md",
    "format_name": "myst"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "source_map": [
   11,
   25,
   41,
   264,
   291,
   298
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}