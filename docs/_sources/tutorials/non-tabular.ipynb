{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6e1be78",
   "metadata": {},
   "source": [
    "# Non-tabular setting\n",
    "\n",
    "`````{margin}\n",
    "````{dropdown} Necessary imports\n",
    "```{code-block} python\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from colosseum.agent.agents.infinite_horizon import (\n",
    "    DQNContinuous,\n",
    "    ActorCriticContinuous,\n",
    ")\n",
    "from colosseum.agent.utils import sample_agent_hyperparameters\n",
    "from colosseum.benchmark import ColosseumDefaultBenchmark\n",
    "from colosseum.emission_maps import (\n",
    "    OneHotEncoding,\n",
    "    StateLinearOptimal,\n",
    "    StateLinearRandom,\n",
    "    TensorEncoding,\n",
    "    ImageEncoding,\n",
    "    StateInfo,\n",
    ")\n",
    "from colosseum.experiment.agent_mdp_interaction import MDPLoop\n",
    "from colosseum.mdp.simple_grid import SimpleGridContinuous\n",
    "from colosseum.utils import make_mdp_spec\n",
    "```\n",
    "````\n",
    "`````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a838df08",
   "metadata": {
    "tags": [
     "remove-output",
     "remove-input"
    ]
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'BaseActor' from 'colosseum.agent.actors' (/home/michelangelo/PycharmProjects/Colosseum/colosseum/agent/actors/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_46242/1075295236.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m from colosseum.agent.agents.infinite_horizon import (\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mDQNContinuous\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mActorCriticContinuous\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/Colosseum/colosseum/agent/agents/infinite_horizon/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcolosseum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfinite_horizon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboot_dqn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBootDQNContinuous\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcolosseum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfinite_horizon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdqn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDQNContinuous\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m from colosseum.agent.agents.infinite_horizon.posterior_sampling import (\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mPSRLContinuous\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m )\n",
      "\u001b[0;32m~/PycharmProjects/Colosseum/colosseum/agent/agents/infinite_horizon/posterior_sampling.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mray\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtune\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcolosseum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactors\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mQValuesActor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcolosseum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseAgent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcolosseum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmdp_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbayesian_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBayesianMDPModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/Colosseum/colosseum/agent/actors/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcolosseum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQ_values_actor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mQValuesActor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcolosseum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseActor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcolosseum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomActor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/Colosseum/colosseum/agent/actors/Q_values_actor.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcolosseum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactors\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseActor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcolosseum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macme\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMDPSpec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'BaseActor' from 'colosseum.agent.actors' (/home/michelangelo/PycharmProjects/Colosseum/colosseum/agent/actors/__init__.py)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices(\"GPU\")\n",
    "try:\n",
    "    # Disable all GPUS\n",
    "    tf.config.set_visible_devices([], \"GPU\")\n",
    "    visible_devices = tf.config.get_visible_devices()\n",
    "    for device in visible_devices:\n",
    "        assert device.device_type != \"GPU\"\n",
    "except:\n",
    "    # Invalid device or cannot modify virtual devices once initialized.\n",
    "    pass\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from colosseum.agent.agents.infinite_horizon import (\n",
    "    DQNContinuous,\n",
    "    ActorCriticContinuous,\n",
    ")\n",
    "from colosseum.agent.utils import sample_agent_hyperparameters\n",
    "from colosseum.benchmark import ColosseumDefaultBenchmark\n",
    "from colosseum.emission_maps import (\n",
    "    OneHotEncoding,\n",
    "    StateLinearOptimal,\n",
    "    StateLinearRandom,\n",
    "    TensorEncoding,\n",
    "    ImageEncoding,\n",
    "    StateInfo,\n",
    ")\n",
    "from colosseum.experiment.agent_mdp_interaction import MDPLoop\n",
    "from colosseum.mdp.simple_grid import SimpleGridContinuous\n",
    "from colosseum.utils import make_mdp_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29aaf3df",
   "metadata": {},
   "source": [
    "{{col}} is primarily developed for the tabular {{rl}} setting.\n",
    "However, as our goal is to develop principled non-tabular benchmarks, we offer a way to test non-tabular {{rl}}\n",
    "algorithms on the default {{col}} benchmark. Although our benchmark defines a challenge that is well characterized for\n",
    "tabular agents, we believe that it can provide valuable insights into the performance of non-tabular algorithms.\n",
    "\n",
    "The _BlockMDP_ model `cite`{du2019provably} enables us to define non-tabular versions of tabular MDPs.\n",
    "A BlockMDP is a tuple $\\left(\\mathcal S, \\mathcal A, P, P_0, R, \\mathcal O, q\\right)$, where\n",
    "$\\mathcal S$ is the tabular state space,\n",
    "$\\mathcal A$ is the action space,\n",
    "$P$ is the transition kernel,\n",
    "$P_0$ is the starting state distribution,\n",
    "$R$ is the reward kernel,\n",
    "$\\mathcal O$ is the non-tabular observation space, and\n",
    "$q : \\mathcal S \\to \\Delta(\\mathcal O)$ is a (possibly stochastic) _emission map_ that associates a distribution over the observation\n",
    "space to each state in the MDP.\n",
    "Note that the agent is not provided with any information on the state space $\\mathcal S$.\n",
    "\n",
    "Six deterministic emission maps are available. We present them below for the\n",
    "[``SimpleGridContinuous``](../pdoc_files/colosseum/mdp/simple_grid/base.html#SimpleGridContinuous) MDP class.\n",
    "\n",
    "**One-hot encoding**\n",
    "The [`OneHotEncoding`](../pdoc_files/colosseum/emission_maps/one_hot_encoding.html#OneHotEncoding) emission map assigns\n",
    "to each state a feature vector that is filled with zeros except an index that uniquely corresponds to the state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f234c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdp = SimpleGridContinuous(seed=42, size=4, emission_map=OneHotEncoding)\n",
    "ts = mdp.reset()\n",
    "\n",
    "print(\"Observation for the OneHotEncoding emission map.\")\n",
    "print(ts.observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2bfe23",
   "metadata": {},
   "source": [
    "**Linear optimal value**\n",
    "The [`StateLinearOptimal`](../pdoc_files/colosseum/emission_maps/state_linear_optimal.html#StateLinearOptimal)\n",
    "emission map assigns to each state a feature vector $\\phi(s)$ that enables linear representation of the optimal value\n",
    "function. In other words, there is a $\\theta$ such that $V^*(s) = \\theta^T\\phi(s)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a652ea59",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdp = SimpleGridContinuous(seed=42, size=4, emission_map=StateLinearOptimal)\n",
    "ts = mdp.reset()\n",
    "\n",
    "print(\"Observation for the StateLinearOptimal emission map.\")\n",
    "print(ts.observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33162ba4",
   "metadata": {},
   "source": [
    "**Linear random value**\n",
    "The [`StateLinearRandom`](../pdoc_files/colosseum/emission_maps/state_linear_random.html#StateLinearRandom)\n",
    "emission map assigns to each state a feature vector $\\phi(s)$ that enables linear representation of the value function\n",
    "of the randomly acting policy. In other words, there is a $\\theta$ such that $V^\\pi(s) = \\theta^T\\phi(s)$, where $\\pi$\n",
    "is the randomly acting policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fb8a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdp = SimpleGridContinuous(seed=42, size=4, emission_map=StateLinearRandom)\n",
    "ts = mdp.reset()\n",
    "\n",
    "print(\"Observation for the StateLinearRandom emission map.\")\n",
    "print(ts.observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf4252e",
   "metadata": {},
   "source": [
    "Before presenting the `StateInfo`, `ImageEncoding`, and `TensorEncoding` emission maps, we review the textual\n",
    "representation of the `SimpleGridContinuous`, which is used by those emission maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4f46c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdp = SimpleGridContinuous(seed=42, size=4)\n",
    "mdp.reset()\n",
    "print(\"Textual representation.\")\n",
    "print(mdp.get_grid_representation(mdp.cur_node))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913edaf1",
   "metadata": {},
   "source": [
    "The letter A encodes the position of the agent and the symbols $+$ and $-$\n",
    "represent the states that yield large reward and zero reward.\n",
    "\n",
    "**State information**\n",
    "The [`StateInfo`](../pdoc_files/colosseum/emission_maps/state_info.html#StateInfo) emission map assigns to each state\n",
    "a feature vector that contains uniquely identifying information about the state (e.g., coordinates for the DeepSea family)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6d63a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdp = SimpleGridContinuous(seed=42, size=4, emission_map=StateInfo)\n",
    "ts = mdp.reset()\n",
    "\n",
    "print(\"Observation for the StateInfo emission map.\")\n",
    "print(ts.observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bd243a",
   "metadata": {},
   "source": [
    "The observation vector corresponds to the x and y coordinates of the position of the agent.\n",
    "\n",
    "**Image encoding**  \n",
    "The [`ImageEncoding`](../pdoc_files/colosseum/emission_maps/image_encoding.html#ImageEncoding) emission map assigns to\n",
    "each state a feature vector that contains uniquely identifying information about the state (e.g., coordinates for the\n",
    "`DeepSea` mdp class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefad606",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdp = SimpleGridContinuous(seed=42, size=4, emission_map=ImageEncoding)\n",
    "ts = mdp.reset()\n",
    "\n",
    "print(\"Observation for the ImageEncoding emission map.\")\n",
    "print(ts.observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56d3c2c",
   "metadata": {},
   "source": [
    "In the observation matrix, $1$ corresponds to the position of the agent, $2$ to positive rewarding states, and $3$ to\n",
    "non-rewarding states. The rest of the matrix is filled with zeros.\n",
    "\n",
    "**Tensor encoding**\n",
    "The [`TensorEncoding`](../pdoc_files/colosseum/emission_maps/tensor_encoding.html#TensorEncoding) emission map assigns\n",
    "to each state a tensor composed of the concatenation of matrices that one-hot encode the presence of a symbol in the\n",
    "corresponding indices. For example, for the DeepSea family, the tensor is composed of a matrix that encodes the position\n",
    "of the agent and a matrix that encodes the positions of white spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61adebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdp = SimpleGridContinuous(seed=42, size=4, emission_map=TensorEncoding)\n",
    "ts = mdp.reset()\n",
    "\n",
    "print(\"Observation for the TensorEncoding emission map.\")\n",
    "print(ts.observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4367e84b",
   "metadata": {},
   "source": [
    "Similarly to the ImageEncoding emission map, each element of the textual representation is encoded differently.\n",
    "In the TensorEncoding emission map, a one-hot encoding is used.\n",
    "\n",
    "\n",
    "## Non-tabular agent/MDP interactions\n",
    "Analysing the performances of non-tabular agents follows the same API of the tabular case.\n",
    "We present an example below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8ca091",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "optimization_horizon = 2_000\n",
    "\n",
    "# Instantiate the MDP\n",
    "mdp = SimpleGridContinuous(seed=42, size=4, emission_map=TensorEncoding)\n",
    "\n",
    "# DQN\n",
    "boot_dqn = DQNContinuous(\n",
    "    seed=seed,\n",
    "    mdp_specs=make_mdp_spec(mdp),\n",
    "    optimization_horizon=optimization_horizon,\n",
    "    **sample_agent_hyperparameters(DQNContinuous, seed),\n",
    ")\n",
    "\n",
    "# Perform the agent/MDP interaction\n",
    "loop_dqn = MDPLoop(mdp, boot_dqn)\n",
    "loop_dqn.run(T=optimization_horizon, log_every=10)\n",
    "\n",
    "# ActorCritic\n",
    "actor_critic = ActorCriticContinuous(\n",
    "    mdp_specs=make_mdp_spec(mdp),\n",
    "    seed=seed,\n",
    "    optimization_horizon=optimization_horizon,\n",
    "    **sample_agent_hyperparameters(ActorCriticContinuous, seed),\n",
    ")\n",
    "loop_ac = MDPLoop(mdp, actor_critic)\n",
    "loop_ac.run(T=optimization_horizon, log_every=10)\n",
    "\n",
    "# Plot the cumulative regret of the agents\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 4))\n",
    "loop_dqn.plot(ax=ax, baselines=[])\n",
    "loop_ac.plot(ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5beb4699",
   "metadata": {},
   "source": [
    "## Non-tabular hyperparameters optimization and benchmarking\n",
    "\n",
    "Similarly, the hyperparameters optimization and benchmarking procedures for the non-tabular setting can be carried out\n",
    "in the exact same way as for the tabular case.\n",
    "\n",
    "In order to obtain the default {{col}} benchmarks, it is only required to set `non_tabular=True` when calling the\n",
    "`get_benchmark` function as shown below.\n",
    "\n",
    "```{code-block} python\n",
    "ColosseumDefaultBenchmark.CONTINUOUS_ERGODIC.get_benchmark(\n",
    "    \"non_tabular_ce\", non_tabular=True\n",
    ")\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "md:myst",
   "text_representation": {
    "extension": ".md",
    "format_name": "myst"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "source_map": [
   11,
   40,
   77,
   102,
   108,
   114,
   120,
   127,
   133,
   137,
   142,
   149,
   155,
   162,
   168,
   177,
   183,
   193,
   227
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}